# –î–∏–ø–ª–æ–º–Ω–∞—è —Ä–∞–±–æ—Ç–∞: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–∞ Group and Shuffle –∫ GNN-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º

## üìã –û–±–∑–æ—Ä –ø—Ä–æ–µ–∫—Ç–∞

### –ú–µ—Ç–æ–¥ –∏–∑ —Å—Ç–∞—Ç—å–∏ Gorbunov and Yudin "Group and Shuffle"

- **–°—É—Ç—å**: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–∞—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏—è —Å –±–ª–æ—á–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
- **–û—Ç–ª–∏—á–∏–µ –æ—Ç expRNN**: –ú–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–±—ã–ª–æ O(n¬≤) —Å—Ç–∞–ª–æ O(p√ón))
- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ**: Fine-tuning, –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–µ —Å–≤–µ—Ä—Ç–∫–∏, 1-Lipschitz —Å–µ—Ç–∏
- **–î–ª—è –º–æ–µ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è**: –ë–æ—Ä—å–±–∞ —Å over-smoothing —á–µ—Ä–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥–µ–æ–º–µ—Ç—Ä–∏–∏

---

## üìä –î–∞—Ç–∞—Å–µ—Ç—ã

- ‚úÖ **Movielens** (MovieLens-1M)
- ‚úÖ **Amazon-Book**
- ‚ö†Ô∏è **–ù—É–∂–µ–Ω –µ—â–µ –æ–¥–∏–Ω** (–ø—Ä–µ–¥–ª–æ–∂–µ–Ω—ã: Yelp2018, Gowalla)

**–í–æ–ø—Ä–æ—Å –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è**: –ö–∞–∫–æ–π —Ç—Ä–µ—Ç–∏–π –¥–∞—Ç–∞—Å–µ—Ç –±—É–¥–µ—Ç –≤—ã–±—Ä–∞–Ω? (Yelp2018 –∏–ª–∏ Gowalla?)

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏

### GroupShuffleGCNLayer

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–ª–æ—è –≤–∫–ª—é—á–∞–µ—Ç:

1. **–ê–≥—Ä–µ–≥–∞—Ü–∏—è —Å–æ—Å–µ–¥–µ–π (GCN)** - —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è –≥—Ä–∞—Ñ–æ–≤–æ–π —Å–≤–µ—Ä—Ç–∫–∏
2. **Group & Shuffle –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ** - –∫–ª—é—á–µ–≤–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –º–µ—Ç–æ–¥–∞
3. **Residual connections** - –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–ª–æ–µ–≤
4. **Layer aggregation** - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –∏–∑ –≤—Å–µ—Ö —Å–ª–æ–µ–≤

---

## üéØ –ù–æ–≤–∏–∑–Ω–∞ —Ä–∞–±–æ—Ç—ã

1. ‚úÖ **–ü–µ—Ä–≤–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ Group and Shuffle –∫ GNN-—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º**
2. ‚úÖ **–ù–æ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è –±–æ—Ä—å–±—ã —Å over-smoothing**
3. ‚úÖ **–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ –∏–∑–æ–º–µ—Ç—Ä–∏—é**
4. ‚úÖ **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏—è**

---

## üéØ –¶–µ–ª–∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

1. –¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏ –æ–±–æ—Å–Ω–æ–≤–∞—Ç—å —Å–≤—è–∑—å –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ over-smoothing
2. –†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
3. –ü—Ä–æ–≤–µ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –Ω–∞ 4 –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö —Å 6+ baseline –º–µ—Ç–æ–¥–∞–º–∏
4. **Depth analysis** (2, 4, 8, 16 —Å–ª–æ–µ–≤)
5. **Ablation studies** (–∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤)

---

## üìê –ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è

### –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—Å–∫–æ–≤**: 5 –∑–∞–ø—É—Å–∫–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ seeds
- **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã**: t-test, p-values
- **–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π**:
  - Recall@K (K=10, 20, 50)
  - NDCG@K (K=10, 20, 50)
  - Coverage
- **–ú–µ—Ç—Ä–∏–∫–∏ over-smoothing**:
  - Cosine Similarity (–ø–æ —Å–ª–æ—è–º)
  - MAD (Mean Average Distance)
  - Embedding Variance

### –¢–∏–ø—ã –∞–Ω–∞–ª–∏–∑–æ–≤

1. **Depth analysis** - –∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –≥–ª—É–±–∏–Ω—ã —Å–µ—Ç–∏
2. **Ablation studies** - –∞–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
3. **Efficiency analysis** - –∞–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
4. **Visualization** - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

gnn-recommendations/
‚îÇ
‚îú‚îÄ‚îÄ config/                           # ‚öôÔ∏è –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò
‚îÇ   ‚îú‚îÄ‚îÄ datasets/                     # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ movielens1m.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yelp2018.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ amazon_book.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gowalla.yaml
‚îÇ   ‚îú‚îÄ‚îÄ models/                       # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bpr_mf.yaml              # Baseline 1
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lightgcn.yaml            # Baseline 2
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gcnii.yaml               # Baseline 3
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dgr.yaml                 # Baseline 4
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ svd_gcn.yaml             # Baseline 5
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layergcn.yaml            # Baseline 6
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ groupshuffle_gnn.yaml    # ‚≠ê –í–ê–® –ê–õ–ì–û–†–ò–¢–ú
‚îÇ   ‚îî‚îÄ‚îÄ training.yaml                # –û–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è
‚îÇ
‚îú‚îÄ‚îÄ data/                            # üíæ –î–ê–ù–ù–´–ï
‚îÇ   ‚îú‚îÄ‚îÄ raw/                         # –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (—Å–∫–∞—á–∞–Ω–Ω—ã–µ)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ movielens1m/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yelp2018/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ amazon_book/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gowalla/
‚îÇ   ‚îú‚îÄ‚îÄ processed/                   # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ {dataset_name}/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ train.txt
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ valid.txt
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ test.txt
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ stats.json
‚îÇ   ‚îî‚îÄ‚îÄ graphs/                      # –ì—Ä–∞—Ñ—ã (adjacency matrices)
‚îÇ       ‚îî‚îÄ‚îÄ {dataset_name}/
‚îÇ           ‚îú‚îÄ‚îÄ adj_matrix.npz
‚îÇ           ‚îî‚îÄ‚îÄ norm_adj_matrix.npz
‚îÇ
‚îú‚îÄ‚îÄ src/                             # üíª –ò–°–•–û–î–ù–´–ô –ö–û–î
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/                        # üìä DATA PIPELINE
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py               # ‚ö° –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py         # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ graph_builder.py         # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                      # üß† –ú–û–î–ï–õ–ò
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                  # –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ baselines/               # üìå 6 BASELINE –ú–ï–¢–û–î–û–í
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bpr_mf.py           # Baseline 1: BPR-MF
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lightgcn.py         # Baseline 2: LightGCN
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gcnii.py            # Baseline 3: GCNII
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dgr.py              # Baseline 4: DGR
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ svd_gcn.py          # Baseline 5: SVD-GCN
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ layergcn.py         # Baseline 6: LayerGCN
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ group_shuffle/           # ‚≠ê –í–ê–® –ê–õ–ì–û–†–ò–¢–ú
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ layers.py            # GroupShuffleLayer
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ model.py             # GroupShuffleGNN (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ utils.py             # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training/                    # üèãÔ∏è –û–ë–£–ß–ï–ù–ò–ï
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py               # –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å Trainer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ losses.py                # BPR Loss –∏ –¥—Ä—É–≥–∏–µ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py               # Recall@K, NDCG@K, etc.
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/                  # üìà –û–¶–ï–ù–ö–ê
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py             # Evaluator –¥–ª—è –º–µ—Ç—Ä–∏–∫
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ oversmoothing.py         # –ê–Ω–∞–ª–∏–∑ over-smoothing
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                       # üõ†Ô∏è –£–¢–ò–õ–ò–¢–´
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ logger.py                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îÇ       ‚îú‚îÄ‚îÄ visualization.py         # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
‚îÇ       ‚îî‚îÄ‚îÄ statistics.py            # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
‚îÇ
‚îú‚îÄ‚îÄ scripts/                         # üöÄ –ó–ê–ü–£–°–ö –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í
‚îÇ   ‚îú‚îÄ‚îÄ run_experiments.py           # ‚ö° –ì–õ–ê–í–ù–´–ô –°–ö–†–ò–ü–¢
‚îÇ   ‚îú‚îÄ‚îÄ train_single_model.py        # –û–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_model.py            # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îî‚îÄ‚îÄ analyze_results.py           # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
‚îÇ
‚îú‚îÄ‚îÄ experiments/                     # üî¨ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´
‚îÇ   ‚îú‚îÄ‚îÄ depth_analysis/              # –ê–Ω–∞–ª–∏–∑ –≥–ª—É–±–∏–Ω—ã (2,4,8,16 —Å–ª–æ—ë–≤)
‚îÇ   ‚îú‚îÄ‚îÄ ablations/                   # Ablation studies
‚îÇ   ‚îú‚îÄ‚îÄ efficiency/                  # –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
‚îÇ   ‚îî‚îÄ‚îÄ oversmoothing/               # –ê–Ω–∞–ª–∏–∑ over-smoothing
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                       # üìì JUPYTER NOTEBOOKS
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_model_analysis.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_results_visualization.ipynb
‚îÇ
‚îú‚îÄ‚îÄ results/                         # üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/                 # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ logs/                        # –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ metrics/                     # CSV —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
‚îÇ   ‚îî‚îÄ‚îÄ figures/                     # –ì—Ä–∞—Ñ–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
‚îÇ
‚îú‚îÄ‚îÄ tests/                           # ‚úÖ –¢–ï–°–¢–´
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py                 # –¢–µ—Å—Ç—ã data pipeline
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py               # –¢–µ—Å—Ç—ã –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îú‚îÄ‚îÄ test_training.py             # –¢–µ—Å—Ç—ã –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ test_evaluation.py           # –¢–µ—Å—Ç—ã –æ—Ü–µ–Ω–∫–∏
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                 # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ setup.py                         # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–∫–µ—Ç–∞
‚îî‚îÄ‚îÄ README.md                        # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è

---

## üìä –ß–ê–°–¢–¨ 1: 6 –û–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö Baseline –ú–µ—Ç–æ–¥–æ–≤

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –Ω–∞–±–æ—Ä baseline –º–µ—Ç–æ–¥–æ–≤

#### 1. BPR-MF ‚≠ê‚≠ê‚≠ê (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)

- **–°–ª–æ–∂–Ω–æ—Å—Ç—å**: ‚≠ê –õ–ï–ì–ö–û
- **–¢–∏–ø**: –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π CF baseline
- **–û–∂–∏–¥–∞–µ–º—ã–π Recall@10**: 0.045-0.052
- **–û–ø–∏—Å–∞–Ω–∏–µ**: –ë–∞–∑–æ–≤—ã–π –º–µ—Ç–æ–¥ –º–∞—Ç—Ä–∏—á–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ —Å BPR loss

#### 2. LightGCN ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (–°–ê–ú–´–ô –í–ê–ñ–ù–´–ô!)

- **–°–ª–æ–∂–Ω–æ—Å—Ç—å**: ‚≠ê‚≠ê –°–†–ï–î–ù–ï
- **–¢–∏–ø**: –°–∏–ª—å–Ω–µ–π—à–∏–π GNN baseline
- **–û–∂–∏–¥–∞–µ–º—ã–π Recall@10**: 0.058-0.065
- **–ö–æ–¥**: https://github.com/gusye1234/LightGCN-PyTorch
- **–û–ø–∏—Å–∞–Ω–∏–µ**: –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è GCN –±–µ–∑ –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–µ–π –∏ –≤–µ—Å–æ–≤

#### 3. GCNII ‚≠ê‚≠ê‚≠ê‚≠ê

- **–°–ª–æ–∂–Ω–æ—Å—Ç—å**: ‚≠ê‚≠ê –°–†–ï–î–ù–ï
- **–¢–∏–ø**: –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π anti-oversmoothing (residual)
- **–û–∂–∏–¥–∞–µ–º—ã–π Recall@10**: 0.062-0.068
- **–ö–æ–¥**: https://github.com/chennnM/GCNII
- **–û–ø–∏—Å–∞–Ω–∏–µ**: GCN —Å residual connections –∏ identity mapping

#### 4. DGR ‚≠ê‚≠ê‚≠ê‚≠ê

- **–°–ª–æ–∂–Ω–æ—Å—Ç—å**: ‚≠ê‚≠ê‚≠ê –°–†–ï–î–ù–ï-–°–õ–û–ñ–ù–û
- **–¢–∏–ø**: Desmoothing framework (2024, —Å–≤–µ–∂–∏–π!)
- **–û–∂–∏–¥–∞–µ–º—ã–π Recall@10**: 0.068-0.074
- **–ö–æ–¥**: https://github.com/YuanchenBei/DGR
- **–û–ø–∏—Å–∞–Ω–∏–µ**: –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –±–æ—Ä—å–±—ã —Å over-smoothing

#### 5. SVD-GCN ‚≠ê‚≠ê‚≠ê

- **–°–ª–æ–∂–Ω–æ—Å—Ç—å**: ‚≠ê‚≠ê‚≠ê –°–†–ï–î–ù–ï-–°–õ–û–ñ–ù–û
- **–¢–∏–ø**: –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥
- **–û–∂–∏–¥–∞–µ–º—ã–π Recall@10**: 0.060-0.066
- **–û–ø–∏—Å–∞–Ω–∏–µ**: GCN —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º SVD –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏

#### 6. LayerGCN ‚≠ê‚≠ê‚≠ê‚≠ê

- **–°–ª–æ–∂–Ω–æ—Å—Ç—å**: ‚≠ê‚≠ê‚≠ê‚≠ê –°–õ–û–ñ–ù–û
- **–¢–∏–ø**: Layer-wise refinement
- **–û–∂–∏–¥–∞–µ–º—ã–π Recall@10**: 0.070-0.076
- **–ö–æ–¥**: https://github.com/enoche/LayerGCN
- **–û–ø–∏—Å–∞–Ω–∏–µ**: –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –ø–æ —Å–ª–æ—è–º

### –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã

- –ï—Å–ª–∏ SVD-GCN —Å–ª–æ–∂–µ–Ω ‚Üí **NGCF**
- –ï—Å–ª–∏ LayerGCN —Å–ª–æ–∂–µ–Ω ‚Üí **AFDGCF**

---

## üíª –ß–ê–°–¢–¨ 3: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ü—Ä–æ–≥—Ä–∞–º–º—ã

### –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
gnn-recommendations/
‚îú‚îÄ‚îÄ config/                    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ YAML
‚îú‚îÄ‚îÄ data/                      # –î–∞—Ç–∞—Å–µ—Ç—ã
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îî‚îÄ‚îÄ graphs/
‚îú‚îÄ‚îÄ src/                       # –ò—Å—Ö–æ–¥–Ω—ã–π –∫–æ–¥
‚îÇ   ‚îú‚îÄ‚îÄ data/                  # Dataset, preprocessing
‚îÇ   ‚îú‚îÄ‚îÄ models/                # –ú–æ–¥–µ–ª–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ baselines/         # 6 baseline –º–µ—Ç–æ–¥–æ–≤
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ group_shuffle/     # –í–∞—à–∞ –º–æ–¥–µ–ª—å
‚îÇ   ‚îú‚îÄ‚îÄ training/              # Trainer, losses, metrics
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/            # Evaluator, over-smoothing
‚îÇ   ‚îî‚îÄ‚îÄ utils/                 # Logger, visualization
‚îú‚îÄ‚îÄ scripts/                   # –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îú‚îÄ‚îÄ experiments/               # Depth analysis, ablations
‚îú‚îÄ‚îÄ notebooks/                 # Jupyter –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
‚îú‚îÄ‚îÄ results/                   # Checkpoints, logs, figures
‚îî‚îÄ‚îÄ tests/                     # Unit tests
```

---

### –ö–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã

#### 1. Data Pipeline

```python
class RecommendationDataset:
    - load_raw_data()
    - preprocess()
    - split(strategy='temporal')
    - build_graph()
```

#### 2. Models

```python
class GroupShuffleGNN(BaseRecommender):
    - GroupShuffleLayer (–≤–∞—à —Å–ª–æ–π)
    - forward()
    - predict()
    - compute_loss()
```

#### 3. Training

```python
class Trainer:
    - train_epoch()
    - validate()
    - early_stopping
    - checkpoint management
```

#### 4. Evaluation

```python
class Evaluator:
    - Recall@K, NDCG@K, Coverage
    - Statistical tests
    
class OversmoothingAnalyzer:
    - Cosine similarity –ø–æ —Å–ª–æ—è–º
    - MAD metrics
```

---

### –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Å—Ç–µ–∫

- **PyTorch** 2.0+
- **PyTorch Geometric** - –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥—Ä–∞—Ñ–∞–º–∏
- **NumPy, SciPy, Pandas** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
- **Matplotlib, Seaborn** - –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- **TensorBoard / Weights & Biases** - –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

**–í–æ–ø—Ä–æ—Å –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è**: –ï—Å—Ç—å –ª–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –≤–µ—Ä—Å–∏—è–º –±–∏–±–ª–∏–æ—Ç–µ–∫?

---

### Timeline —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

| –≠—Ç–∞–ø | –í—Ä–µ–º—è | –°–ª–æ–∂–Ω–æ—Å—Ç—å |
|------|-------|-----------|
| Data pipeline | 1 –Ω–µ–¥–µ–ª—è | ‚≠ê‚≠ê |
| BPR-MF | 1 –¥–µ–Ω—å | ‚≠ê |
| LightGCN | 3-4 –¥–Ω—è | ‚≠ê‚≠ê |
| GCNII | 3-4 –¥–Ω—è | ‚≠ê‚≠ê |
| GroupShuffleGNN | 2 –Ω–µ–¥–µ–ª–∏ | ‚≠ê‚≠ê‚≠ê |
| DGR, LayerGCN | 1 –Ω–µ–¥–µ–ª—è | ‚≠ê‚≠ê‚≠ê |
| SVD-GCN | 5 –¥–Ω–µ–π | ‚≠ê‚≠ê‚≠ê |
| Training/Eval | 1 –Ω–µ–¥–µ–ª—è | ‚≠ê‚≠ê |
| –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã | 2 –Ω–µ–¥–µ–ª–∏ | ‚≠ê‚≠ê |
| **–ò–¢–û–ì–û** | **~4 –º–µ—Å—è—Ü–∞** | |




---

## üéØ –ò–¢–û–ì–û–í–´–ï –í–´–í–û–î–´

### –û—Ç–≤–µ—Ç—ã –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ –≤–æ–ø—Ä–æ—Å—ã

#### 1. –ö–∞–∫–∏–µ 6 –º–µ—Ç–æ–¥–æ–≤?

**Baseline –º–µ—Ç–æ–¥—ã**: BPR-MF, LightGCN, GCNII, DGR, SVD-GCN, LayerGCN

**–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤**:
- –¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–π CF (BPR-MF)
- –ü—Ä–æ—Å—Ç–æ–π GNN (LightGCN)
- Residual connections (GCNII)
- Desmoothing framework (DGR)
- –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥ (SVD-GCN)
- Layer-wise refinement (LayerGCN)

#### 2. –ù–∞ –∫–∞–∫–æ–π —É—Ä–æ–≤–µ–Ω—å –ø–æ—Ç—è–Ω–µ—Ç?

- **–ú–ê–ì–ò–°–¢–†–ê–¢–£–†–ê** (–æ—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞) ‚Äî –µ—Å–ª–∏ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–∞–∫ –≤ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–µ
- **–ê–°–ü–ò–†–ê–ù–¢–£–†–ê** (–Ω–∞—á–∞–ª—å–Ω—ã–π) ‚Äî –µ—Å–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å —Ç–µ–æ—Ä–∏—é —Å –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞–º–∏

#### 3. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã?

- –ú–æ–¥—É–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å 10+ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º–∏
- ~5000-7000 —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞
- –ü–æ–ª–Ω–∞—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å
- 4 –º–µ—Å—è—Ü–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏

---

### –ß—Ç–æ –¥–µ–ª–∞—Ç—å –¥–∞–ª—å—à–µ

1. ‚úÖ –ò–∑—É—á–∏—Ç—å –≤—Å–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (3 –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≥–æ—Ç–æ–≤—ã)
2. ‚úÖ –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
3. ‚úÖ –ù–∞—á–∞—Ç—å —Å data pipeline –∏ BPR-MF
4. ‚úÖ –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å baseline –º–µ—Ç–æ–¥—ã
5. ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –≤–∞—à—É –º–æ–¥–µ–ª—å
6. ‚úÖ –ü—Ä–æ–≤–µ—Å—Ç–∏ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã

---

## üìù –°—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã

- `complete_implementation_guide.md`
- `research_guide_gorbunov_yudin_gnn_recommendations.md`
- `critical_analysis_summary.md`
- `baseline_methods_analysis.md`

---

## üí¨ Feedback –∏ –≤–æ–ø—Ä–æ—Å—ã
—Ç—ã –º–Ω–µ —Å–∫–∏–Ω—É–ª–∞ —Ñ–∞–π–ª complete_implementation_guide.md, –º–Ω–µ –æ–Ω –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è, –Ω–æ –Ω—É–∂–Ω–æ –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –ø–æ—è—Å–Ω–µ–Ω–∏–µ, –º–æ–∂–µ—à—å —Ä–∞—Å—Å–∫–∞–∑–∞—Ç—å –ø—Ä–æ —Å–∞–º –ø–æ—Ç–æ–∫ —Ä–∞–±–æ—Ç—ã —ç—Ç–æ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã, –≥–¥–µ –±—É–¥–µ—Ç –º–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º, –≥–¥–µ 6 –º–µ—Ç–æ–¥–æ–≤ baseline, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –æ–±—Å—É–∂–¥–∞–ª–∏, –≥–¥–µ —Ç–µ—Å—Ç—ã –∏ –∫–∞–∫–∏–µ —Ç–µ—Å—Ç—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –º–Ω–µ –≤–∞–∂–Ω–æ –∏–º–µ–Ω–Ω–æ –ø–æ–Ω—è—Ç—å –æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –±—É–¥—É—é—â–µ–π –ø—Ä–æ–≥—Ä–∞–º–º—ã
–û—Ç–ª–∏—á–Ω–æ! –î–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä—ë–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–≥—Ä–∞–º–º—ã –∏ –ø–æ—Ç–æ–∫ —Ä–∞–±–æ—Ç—ã –ø–æ—à–∞–≥–æ–≤–æ. –Ø –æ–±—ä—è—Å–Ω—é, –≥–¥–µ —á—Ç–æ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∏ –∫–∞–∫ –≤—Å—ë –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç.

---

## üîÑ –ü–û–¢–û–ö –†–ê–ë–û–¢–´ –ü–†–û–ì–†–ê–ú–ú–´

### üìÅ –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê (–¥–µ—Ç–∞–ª—å–Ω–æ)
gnn-recommendations/
‚îÇ
‚îú‚îÄ‚îÄ config/                           # ‚öôÔ∏è –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò
‚îÇ   ‚îú‚îÄ‚îÄ datasets/                     # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ movielens1m.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yelp2018.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ amazon_book.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gowalla.yaml
‚îÇ   ‚îú‚îÄ‚îÄ models/                       # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bpr_mf.yaml              # Baseline 1
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lightgcn.yaml            # Baseline 2
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gcnii.yaml               # Baseline 3
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dgr.yaml                 # Baseline 4
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ svd_gcn.yaml             # Baseline 5
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layergcn.yaml            # Baseline 6
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ groupshuffle_gnn.yaml    # ‚≠ê –í–ê–® –ê–õ–ì–û–†–ò–¢–ú
‚îÇ   ‚îî‚îÄ‚îÄ training.yaml                # –û–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–±—É—á–µ–Ω–∏—è
‚îÇ
‚îú‚îÄ‚îÄ data/                            # üíæ –î–ê–ù–ù–´–ï
‚îÇ   ‚îú‚îÄ‚îÄ raw/                         # –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (—Å–∫–∞—á–∞–Ω–Ω—ã–µ)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ movielens1m/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yelp2018/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ amazon_book/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gowalla/
‚îÇ   ‚îú‚îÄ‚îÄ processed/                   # –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ {dataset_name}/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ train.txt
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ valid.txt
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ test.txt
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ stats.json
‚îÇ   ‚îî‚îÄ‚îÄ graphs/                      # –ì—Ä–∞—Ñ—ã (adjacency matrices)
‚îÇ       ‚îî‚îÄ‚îÄ {dataset_name}/
‚îÇ           ‚îú‚îÄ‚îÄ adj_matrix.npz
‚îÇ           ‚îî‚îÄ‚îÄ norm_adj_matrix.npz
‚îÇ
‚îú‚îÄ‚îÄ src/                             # üíª –ò–°–•–û–î–ù–´–ô –ö–û–î
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/                        # üìä DATA PIPELINE
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py               # ‚ö° –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–∞—Ç–∞—Å–µ—Ç–∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py         # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ graph_builder.py         # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                      # üß† –ú–û–î–ï–õ–ò
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                  # –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ baselines/               # üìå 6 BASELINE –ú–ï–¢–û–î–û–í
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bpr_mf.py           # Baseline 1: BPR-MF
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lightgcn.py         # Baseline 2: LightGCN
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gcnii.py            # Baseline 3: GCNII
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dgr.py              # Baseline 4: DGR
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ svd_gcn.py          # Baseline 5: SVD-GCN
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ layergcn.py         # Baseline 6: LayerGCN
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ group_shuffle/           # ‚≠ê –í–ê–® –ê–õ–ì–û–†–ò–¢–ú
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ layers.py            # GroupShuffleLayer
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ model.py             # GroupShuffleGNN (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ utils.py             # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training/                    # üèãÔ∏è –û–ë–£–ß–ï–ù–ò–ï
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py               # –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å Trainer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ losses.py                # BPR Loss –∏ –¥—Ä—É–≥–∏–µ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metrics.py               # Recall@K, NDCG@K, etc.
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/                  # üìà –û–¶–ï–ù–ö–ê
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py             # Evaluator –¥–ª—è –º–µ—Ç—Ä–∏–∫
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ oversmoothing.py         # –ê–Ω–∞–ª–∏–∑ over-smoothing
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                       # üõ†Ô∏è –£–¢–ò–õ–ò–¢–´
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ logger.py                # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
‚îÇ       ‚îú‚îÄ‚îÄ visualization.py         # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
‚îÇ       ‚îî‚îÄ‚îÄ statistics.py            # –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
‚îÇ
‚îú‚îÄ‚îÄ scripts/                         # üöÄ –ó–ê–ü–£–°–ö –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–û–í
‚îÇ   ‚îú‚îÄ‚îÄ run_experiments.py           # ‚ö° –ì–õ–ê–í–ù–´–ô –°–ö–†–ò–ü–¢
‚îÇ   ‚îú‚îÄ‚îÄ train_single_model.py        # –û–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ evaluate_model.py            # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îî‚îÄ‚îÄ analyze_results.py           # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
‚îÇ
‚îú‚îÄ‚îÄ experiments/                     # üî¨ –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´
‚îÇ   ‚îú‚îÄ‚îÄ depth_analysis/              # –ê–Ω–∞–ª–∏–∑ –≥–ª—É–±–∏–Ω—ã (2,4,8,16 —Å–ª–æ—ë–≤)
‚îÇ   ‚îú‚îÄ‚îÄ ablations/                   # Ablation studies
‚îÇ   ‚îú‚îÄ‚îÄ efficiency/                  # –ê–Ω–∞–ª–∏–∑ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
‚îÇ   ‚îî‚îÄ‚îÄ oversmoothing/               # –ê–Ω–∞–ª–∏–∑ over-smoothing
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                       # üìì JUPYTER NOTEBOOKS
‚îÇ   ‚îú‚îÄ‚îÄ 01_data_exploration.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_model_analysis.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 03_results_visualization.ipynb
‚îÇ
‚îú‚îÄ‚îÄ results/                         # üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/                 # –°–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ logs/                        # –õ–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ metrics/                     # CSV —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
‚îÇ   ‚îî‚îÄ‚îÄ figures/                     # –ì—Ä–∞—Ñ–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
‚îÇ
‚îú‚îÄ‚îÄ tests/                           # ‚úÖ –¢–ï–°–¢–´
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py                 # –¢–µ—Å—Ç—ã data pipeline
‚îÇ   ‚îú‚îÄ‚îÄ test_models.py               # –¢–µ—Å—Ç—ã –º–æ–¥–µ–ª–µ–π
‚îÇ   ‚îú‚îÄ‚îÄ test_training.py             # –¢–µ—Å—Ç—ã –æ–±—É—á–µ–Ω–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ test_evaluation.py           # –¢–µ—Å—Ç—ã –æ—Ü–µ–Ω–∫–∏
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                 # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ setup.py                         # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞–∫–µ—Ç–∞
‚îî‚îÄ‚îÄ README.md                        # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è



---

## üîÑ –ü–û–¢–û–ö –í–´–ü–û–õ–ù–ï–ù–ò–Ø –ü–†–û–ì–†–ê–ú–ú–´

### –≠–¢–ê–ü 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö üìä

**–§–∞–π–ª—ã**: `src/data/dataset.py`, `src/data/preprocessing.py`, `src/data/graph_builder.py`

**–ü—Ä–æ—Ü–µ—Å—Å**:
```
–í–•–û–î: –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (ratings.csv)
  ‚Üì
1. –ó–∞–≥—Ä—É–∑–∫–∞ (dataset.py)
  ‚Üì
2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è (min 10 interactions)
  ‚Üì
3. –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è (implicit feedback)
  ‚Üì
4. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ (train/valid/test - temporal split)
  ‚Üì
5. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ (bipartite user-item graph)
  ‚Üì
–í–´–•–û–î: train.txt, valid.txt, test.txt, adj_matrix.npz
```

**–ü—Ä–∏–º–µ—Ä –∫–æ–¥–∞**:

```python
# src/data/dataset.py
class RecommendationDataset:
    def __init__(self, name, root_dir):
        self.name = name
        self.root_dir = root_dir
    
    def load_raw_data(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        pass
    
    def preprocess(self):
        """–ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è"""
        pass
    
    def split(self, strategy='temporal'):
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/valid/test"""
        pass
    
    def build_graph(self):
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å bipartite –≥—Ä–∞—Ñ"""
        pass
```



---

### –≠–¢–ê–ü 2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π üß†

**–§–∞–π–ª—ã**:
- `src/models/base.py` - –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å
- `src/models/baselines/*.py` - 6 baseline –º–µ—Ç–æ–¥–æ–≤
- `src/models/group_shuffle/*.py` - –≤–∞—à –∞–ª–≥–æ—Ä–∏—Ç–º

**–°–¢–†–£–ö–¢–£–†–ê –ú–û–î–ï–õ–ï–ô**:

```
BaseRecommender (base.py)
    ‚îú‚îÄ‚îÄ BPR_MF (baselines/bpr_mf.py)          ‚Üê Baseline 1
    ‚îú‚îÄ‚îÄ LightGCN (baselines/lightgcn.py)      ‚Üê Baseline 2
    ‚îú‚îÄ‚îÄ GCNII (baselines/gcnii.py)            ‚Üê Baseline 3
    ‚îú‚îÄ‚îÄ DGR (baselines/dgr.py)                ‚Üê Baseline 4
    ‚îú‚îÄ‚îÄ SVD_GCN (baselines/svd_gcn.py)        ‚Üê Baseline 5
    ‚îú‚îÄ‚îÄ LayerGCN (baselines/layergcn.py)      ‚Üê Baseline 6
    ‚îî‚îÄ‚îÄ GroupShuffleGNN (group_shuffle/model.py)  ‚Üê ‚≠ê –í–ê–® –ê–õ–ì–û–†–ò–¢–ú
```


–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å (–≤—Å–µ –º–æ–¥–µ–ª–∏ –Ω–∞—Å–ª–µ–¥—É—é—Ç –æ—Ç –Ω–µ–≥–æ):
# src/models/base.py
class BaseRecommender(nn.Module):
    def __init__(self, n_users, n_items, embedding_dim):
        super().__init__()
        self.n_users = n_users
        self.n_items = n_items
        self.embedding_dim = embedding_dim
    
    def forward(self, users, items):
        """Forward pass - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –≤ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏"""
        raise NotImplementedError
    
    def predict(self, users, items):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ scores –¥–ª—è user-item –ø–∞—Ä"""
        raise NotImplementedError
    
    def get_all_embeddings(self):
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ embeddings (–¥–ª—è evaluation)"""
        raise NotImplementedError


–í–∞—à –∞–ª–≥–æ—Ä–∏—Ç–º:
# src/models/group_shuffle/model.py
class GroupShuffleGNN(BaseRecommender):
    def __init__(self, n_users, n_items, embedding_dim, n_layers, 
                 block_size, residual_alpha):
        super().__init__(n_users, n_items, embedding_dim)
        
        # Embeddings
        self.user_embedding = nn.Embedding(n_users, embedding_dim)
        self.item_embedding = nn.Embedding(n_items, embedding_dim)
        
        # ‚≠ê –í–ê–®–ò –°–õ–û–ò
        self.layers = nn.ModuleList([
            GroupShuffleLayer(embedding_dim, block_size)
            for _ in range(n_layers)
        ])
        
        self.residual_alpha = residual_alpha
    
    def forward(self, adj_matrix):
        """
        adj_matrix: normalized adjacency matrix
        """
        # –ù–∞—á–∞–ª—å–Ω—ã–µ embeddings
        x_init = torch.cat([
            self.user_embedding.weight,
            self.item_embedding.weight
        ], dim=0)
        
        x = x_init
        all_embeddings = [x]
        
        # –ü—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–ª–æ–∏
        for layer in self.layers:
            x_transformed = layer(x, adj_matrix)
            
            # Residual connection
            x = (1 - self.residual_alpha) * x_transformed + \
                self.residual_alpha * x_init
            
            all_embeddings.append(x)
        
        # Layer aggregation
        x_final = torch.mean(torch.stack(all_embeddings), dim=0)
        
        # –†–∞–∑–¥–µ–ª–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ –Ω–∞ users –∏ items
        user_emb, item_emb = torch.split(
            x_final, [self.n_users, self.n_items]
        )
        
        return user_emb, item_emb


GroupShuffleLayer (–≤–∞—à –∫–ª—é—á–µ–≤–æ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç):
# src/models/group_shuffle/layers.py
class GroupShuffleLayer(nn.Module):
    def __init__(self, dim, block_size):
        super().__init__()
        self.dim = dim
        self.block_size = block_size
        self.n_blocks = dim // block_size
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è skew-symmetric –º–∞—Ç—Ä–∏—Ü
        self.skew_params = nn.ParameterList([
            nn.Parameter(torch.randn(block_size, block_size))
            for _ in range(self.n_blocks)
        ])
        
        # Shuffle permutation
        self.register_buffer('perm', self._create_shuffle_permutation())
    
    def _create_shuffle_permutation(self):
        """–°–æ–∑–¥–∞—Ç—å –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫—É –¥–ª—è shuffle"""
        perm = torch.randperm(self.dim)
        return perm
    
    def forward(self, x, adj):
        """
        x: node features [N, dim]
        adj: adjacency matrix [N, N]
        """
        # 1. Graph convolution
        x_conv = torch.sparse.mm(adj, x)  # [N, dim]
        
        # 2. –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É (Group)
        W_orth = self._build_orthogonal_matrix()  # [dim, dim]
        
        # 3. –ü—Ä–∏–º–µ–Ω–∏—Ç—å –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        x_transformed = x_conv @ W_orth  # [N, dim]
        
        # 4. Shuffle
        x_shuffled = x_transformed[:, self.perm]
        
        return x_shuffled
    
    def _build_orthogonal_matrix(self):
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å –±–ª–æ—á–Ω–æ-–¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω—É—é –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É"""
        blocks = []
        for param in self.skew_params:
            # –°–¥–µ–ª–∞—Ç—å skew-symmetric
            A_skew = param - param.T
            
            # Exponential map (Lie group)
            block_orth = torch.matrix_exp(A_skew)
            blocks.append(block_orth)
        
        # –°–æ–±—Ä–∞—Ç—å –±–ª–æ—á–Ω–æ-–¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
        W_orth = torch.block_diag(*blocks)
        return W_orth



–≠–¢–ê–ü 3: –û–±—É—á–µ–Ω–∏–µ üèãÔ∏è
–§–∞–π–ª—ã: src/training/trainer.py, src/training/losses.py
–ü–†–û–¶–ï–°–° –û–ë–£–ß–ï–ù–ò–Ø:

1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
   ‚Üì
2. –î–ª—è –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏:
   ‚îú‚îÄ‚îÄ –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞—Ç—á–µ–π (user, positive_item, negative_item)
   ‚îú‚îÄ‚îÄ Forward pass
   ‚îú‚îÄ‚îÄ –í—ã—á–∏—Å–ª–µ–Ω–∏–µ BPR Loss
   ‚îú‚îÄ‚îÄ Backward pass + –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
   ‚îî‚îÄ‚îÄ –í–∞–ª–∏–¥–∞—Ü–∏—è (–∫–∞–∂–¥—ã–µ N —ç–ø–æ—Ö)
   ‚Üì
3. Early stopping (–µ—Å–ª–∏ validation –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è)
   ‚Üì
4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞


Trainer:
# src/training/trainer.py
class Trainer:
    def __init__(self, model, dataset, config):
        self.model = model
        self.dataset = dataset
        self.config = config
        
        self.optimizer = torch.optim.Adam(
            model.parameters(), 
            lr=config['lr']
        )
        
        self.loss_fn = BPRLoss()
    
    def train_epoch(self):
        """–û–¥–Ω–∞ —ç–ø–æ—Ö–∞ –æ–±—É—á–µ–Ω–∏—è"""
        self.model.train()
        total_loss = 0
        
        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ embeddings –æ–¥–∏–Ω —Ä–∞–∑
        user_emb, item_emb = self.model(self.dataset.adj_matrix)
        
        # –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞—Ç—á–µ–π
        for batch in self.dataset.get_train_batches():
            users, pos_items, neg_items = batch
            
            # Scores
            pos_scores = (user_emb[users] * item_emb[pos_items]).sum(dim=1)
            neg_scores = (user_emb[users] * item_emb[neg_items]).sum(dim=1)
            
            # BPR Loss
            loss = self.loss_fn(pos_scores, neg_scores)
            
            # Backward
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
        
        return total_loss / len(self.dataset.train_batches)
    
    def validate(self):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è"""
        self.model.eval()
        with torch.no_grad():
            metrics = self.evaluator.evaluate(
                self.model, 
                self.dataset.valid_data
            )
        return metrics
    
    def train(self):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"""
        best_metric = 0
        patience_counter = 0
        
        for epoch in range(self.config['max_epochs']):
            # –û–±—É—á–µ–Ω–∏–µ
            train_loss = self.train_epoch()
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è (–∫–∞–∂–¥—ã–µ N —ç–ø–æ—Ö)
            if epoch % self.config['eval_every'] == 0:
                metrics = self.validate()
                
                # Early stopping
                if metrics['recall@10'] > best_metric:
                    best_metric = metrics['recall@10']
                    patience_counter = 0
                    self.save_checkpoint()
                else:
                    patience_counter += 1
                
                if patience_counter >= self.config['patience']:
                    print("Early stopping!")
                    break
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            self.log(epoch, train_loss, metrics)



–≠–¢–ê–ü 4: –û—Ü–µ–Ω–∫–∞ üìà
–§–∞–π–ª—ã: src/evaluation/evaluator.py, src/evaluation/oversmoothing.py
–ú–ï–¢–†–ò–ö–ò:

1. Recommendation Quality:
   ‚îú‚îÄ‚îÄ Recall@K (K=10,20,50)
   ‚îú‚îÄ‚îÄ Precision@K
   ‚îú‚îÄ‚îÄ NDCG@K
   ‚îî‚îÄ‚îÄ Coverage

2. Over-smoothing Analysis:
   ‚îú‚îÄ‚îÄ Cosine Similarity (–ø–æ —Å–ª–æ—è–º)
   ‚îú‚îÄ‚îÄ MAD (Mean Average Distance)
   ‚îî‚îÄ‚îÄ Embedding Variance


Evaluator:
# src/evaluation/evaluator.py
class Evaluator:
    def __init__(self, k_values=[10, 20, 50]):
        self.k_values = k_values
    
    def evaluate(self, model, test_data):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        model.eval()
        
        # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ embeddings
        user_emb, item_emb = model.get_all_embeddings()
        
        # –í—ã—á–∏—Å–ª–∏—Ç—å scores –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä
        scores = user_emb @ item_emb.T  # [n_users, n_items]
        
        metrics = {}
        for k in self.k_values:
            metrics[f'recall@{k}'] = self.recall_at_k(scores, test_data, k)
            metrics[f'ndcg@{k}'] = self.ndcg_at_k(scores, test_data, k)
        
        return metrics
    
    def recall_at_k(self, scores, test_data, k):
        """Recall@K"""
        # –¢–æ–ø-K –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        _, top_k_items = torch.topk(scores, k, dim=1)
        
        # –°—Ä–∞–≤–Ω–∏—Ç—å —Å ground truth
        hits = 0
        total = 0
        for user_id, true_items in test_data.items():
            pred_items = top_k_items[user_id].tolist()
            hits += len(set(pred_items) & set(true_items))
            total += len(true_items)
        
        return hits / total


Over-smoothing Analyzer:
# src/evaluation/oversmoothing.py
class OversmoothingAnalyzer:
    def analyze(self, model, dataset):
        """–ê–Ω–∞–ª–∏–∑ over-smoothing"""
        model.eval()
        
        # –ü–æ–ª—É—á–∏—Ç—å embeddings –ø–æ —Å–ª–æ—è–º
        layer_embeddings = model.get_layer_embeddings(dataset.adj_matrix)
        
        metrics = {}
        for i, emb in enumerate(layer_embeddings):
            # Cosine similarity –º–µ–∂–¥—É –≤—Å–µ–º–∏ –ø–∞—Ä–∞–º–∏ –Ω–æ–¥–æ–≤
            cos_sim = self.cosine_similarity_matrix(emb)
            metrics[f'layer_{i}_mean_cos_sim'] = cos_sim.mean().item()
            
            # MAD (Mean Average Distance)
            mad = self.mean_average_distance(emb)
            metrics[f'layer_{i}_mad'] = mad
        
        return metrics



–≠–¢–ê–ü 5: –ó–∞–ø—É—Å–∫ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ üöÄ
–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç: scripts/run_experiments.py
–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´:

1. Depth Analysis (–≥–ª—É–±–∏–Ω–∞ 2, 4, 8, 16)
   ‚Üì
2. Ablation Studies (–±–µ–∑ residual, –±–µ–∑ shuffle, –∏ —Ç.–¥.)
   ‚Üì
3. Comparison —Å baseline –º–µ—Ç–æ–¥–∞–º–∏
   ‚Üì
4. Over-smoothing Analysis
   ‚Üì
5. Statistical Significance Tests


–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç:
# scripts/run_experiments.py
def main():
    # 1. –ó–∞–≥—Ä—É–∑–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    datasets = ['movielens1m', 'yelp2018', 'amazon_book', 'gowalla']
    models = [
        'bpr_mf',        # Baseline 1
        'lightgcn',      # Baseline 2
        'gcnii',         # Baseline 3
        'dgr',           # Baseline 4
        'svd_gcn',       # Baseline 5
        'layergcn',      # Baseline 6
        'groupshuffle'   # ‚≠ê –í–ê–® –ê–õ–ì–û–†–ò–¢–ú
    ]
    
    results = {}
    
    # 2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    for dataset_name in datasets:
        dataset = load_dataset(dataset_name)
        
        # 3. –î–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        for model_name in models:
            print(f"\n{'='*50}")
            print(f"Training {model_name} on {dataset_name}")
            print(f"{'='*50}\n")
            
            # –ó–∞–ø—É—Å—Ç–∏—Ç—å 5 runs —Å —Ä–∞–∑–Ω—ã–º–∏ seeds
            run_results = []
            for seed in range(5):
                set_seed(seed)
                
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
                model = create_model(model_name, dataset.config)
                trainer = Trainer(model, dataset, config)
                
                # –û–±—É—á–µ–Ω–∏–µ
                trainer.train()
                
                # –û—Ü–µ–Ω–∫–∞
                metrics = evaluator.evaluate(model, dataset.test_data)
                run_results.append(metrics)
            
            # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (mean ¬± std)
            results[f'{dataset_name}_{model_name}'] = aggregate_results(run_results)
    
    # 4. –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    save_results(results, 'results/metrics/all_results.csv')
    
    # 5. –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
    perform_statistical_tests(results)
    
    # 6. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plot_comparison(results)



‚úÖ –¢–ï–°–¢–´ (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–ï)
–§–∞–π–ª—ã: tests/test_*.py*_
1. –¢–µ—Å—Ç—ã Data Pipeline (tests/test_data.py)
import pytest

def test_data_loading():
    """–¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    dataset = RecommendationDataset('movielens1m')
    dataset.load_raw_data()
    assert dataset.raw_data is not None
    assert len(dataset.raw_data) > 0

def test_preprocessing():
    """–¢–µ—Å—Ç –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞"""
    dataset = RecommendationDataset('movielens1m')
    dataset.preprocess()
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –Ω–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π/–∞–π—Ç–µ–º–æ–≤ —Å < 10 interactions
    assert all(dataset.user_counts >= 10)
    assert all(dataset.item_counts >= 10)

def test_train_test_split():
    """–¢–µ—Å—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ train/test"""
    dataset = RecommendationDataset('movielens1m')
    dataset.split(strategy='temporal')
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –Ω–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
    train_interactions = set(dataset.train_data)
    test_interactions = set(dataset.test_data)
    assert len(train_interactions & test_interactions) == 0

def test_graph_construction():
    """–¢–µ—Å—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞"""
    dataset = RecommendationDataset('movielens1m')
    adj_matrix = dataset.build_graph()
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
    n_nodes = dataset.n_users + dataset.n_items
    assert adj_matrix.shape == (n_nodes, n_nodes)
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ—Å—Ç—å (bipartite –≥—Ä–∞—Ñ)
    assert torch.allclose(adj_matrix, adj_matrix.T)


2. –¢–µ—Å—Ç—ã –ú–æ–¥–µ–ª–µ–π (tests/test_models.py)
def test_groupshuffle_layer_orthogonality():
    """‚≠ê –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –¢–ï–°–¢: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –º–∞—Ç—Ä–∏—Ü–∞ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–∞"""
    layer = GroupShuffleLayer(dim=128, block_size=32)
    W_orth = layer._build_orthogonal_matrix()
    
    # W^T @ W –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–ª–∏–∑–∫–æ –∫ Identity
    identity = W_orth.T @ W_orth
    expected = torch.eye(128)
    
    assert torch.allclose(identity, expected, atol=1e-5)

def test_model_forward_pass():
    """–¢–µ—Å—Ç forward pass –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
    models = [
        BPR_MF, LightGCN, GCNII, DGR, SVD_GCN, LayerGCN, GroupShuffleGNN
    ]
    
    for ModelClass in models:
        model = ModelClass(n_users=100, n_items=200, embedding_dim=64)
        adj_matrix = create_dummy_adj_matrix(300, 300)
        
        # Forward pass
        user_emb, item_emb = model(adj_matrix)
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
        assert user_emb.shape == (100, 64)
        assert item_emb.shape == (200, 64)

def test_model_gradient_flow():
    """–¢–µ—Å—Ç, —á—Ç–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å"""
    model = GroupShuffleGNN(n_users=100, n_items=200, embedding_dim=64, n_layers=3)
    adj_matrix = create_dummy_adj_matrix(300, 300)
    
    # Forward + backward
    user_emb, item_emb = model(adj_matrix)
    loss = user_emb.sum() + item_emb.sum()
    loss.backward()
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–µ None
    for param in model.parameters():
        assert param.grad is not None

def test_embedding_dimensions():
    """–¢–µ—Å—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π embeddings"""
    model = GroupShuffleGNN(n_users=943, n_items=1682, embedding_dim=64, n_layers=3)
    
    assert model.user_embedding.weight.shape == (943, 64)
    assert model.item_embedding.weight.shape == (1682, 64)


3. –¢–µ—Å—Ç—ã –û–±—É—á–µ–Ω–∏—è (tests/test_training.py)
def test_bpr_loss():
    """–¢–µ—Å—Ç BPR Loss"""
    loss_fn = BPRLoss()
    
    pos_scores = torch.tensor([2.0, 3.0, 1.5])
    neg_scores = torch.tensor([1.0, 1.5, 0.5])
    
    loss = loss_fn(pos_scores, neg_scores)
    
    # Loss –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º
    assert loss.item() > 0

def test_trainer_one_epoch():
    """–¢–µ—Å—Ç –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏ –æ–±—É—á–µ–Ω–∏—è"""
    model = GroupShuffleGNN(n_users=100, n_items=200, embedding_dim=64, n_layers=2)
    dataset = create_dummy_dataset()
    trainer = Trainer(model, dataset, config={'lr': 0.001})
    
    initial_params = [p.clone() for p in model.parameters()]
    
    # –û–¥–Ω–∞ —ç–ø–æ—Ö–∞
    loss = trainer.train_epoch()
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑–º–µ–Ω–∏–ª–∏—Å—å
    for p_init, p_current in zip(initial_params, model.parameters()):
        assert not torch.allclose(p_init, p_current)
    
    # Loss –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫–æ–Ω–µ—á–Ω—ã–º
    assert not torch.isnan(torch.tensor(loss))

def test_early_stopping():
    """–¢–µ—Å—Ç early stopping"""
    model = GroupShuffleGNN(n_users=100, n_items=200, embedding_dim=64, n_layers=2)
    dataset = create_dummy_dataset()
    trainer = Trainer(model, dataset, config={'patience': 3})
    
    # –°–∏–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —É—Ö—É–¥—à–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    trainer.best_metric = 0.5
    for _ in range(5):
        trainer.validate()  # –ú–µ—Ç—Ä–∏–∫–∞ –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è
    
    # –î–æ–ª–∂–µ–Ω –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
    assert trainer.should_stop == True


4. –¢–µ—Å—Ç—ã Evaluation (tests/test_evaluation.py)
def test_recall_at_k():
    """–¢–µ—Å—Ç Recall@K"""
    evaluator = Evaluator(k_values=[10])
    
    # Dummy –¥–∞–Ω–Ω—ã–µ
    scores = torch.randn(10, 20)  # 10 users, 20 items
    test_data = {0: [1, 5, 10], 1: [2, 7]}
    
    recall = evaluator.recall_at_k(scores, test_data, k=10)
    
    # Recall –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ [0, 1]
    assert 0 <= recall <= 1

def test_oversmoothing_analyzer():
    """–¢–µ—Å—Ç –∞–Ω–∞–ª–∏–∑–∞ over-smoothing"""
    analyzer = OversmoothingAnalyzer()
    
    # –°–æ–∑–¥–∞—Ç—å embeddings —Å —Ä–∞–∑–Ω–æ–π —Å—Ç–µ–ø–µ–Ω—å—é over-smoothing
    emb_layer0 = torch.randn(100, 64)
    emb_layer10 = torch.ones(100, 64)  # –ü–æ–ª–Ω–æ—Å—Ç—å—é collapsed
    
    cos_sim_0 = analyzer.mean_cosine_similarity(emb_layer0)
    cos_sim_10 = analyzer.mean_cosine_similarity(emb_layer10)
    
    # Layer 10 –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –±–æ–ª–µ–µ –≤—ã—Å–æ–∫—É—é similarity
    assert cos_sim_10 > cos_sim_0



---

## üìä –ò–¢–û–ì–û–í–ê–Ø –ö–ê–†–¢–ò–ù–ê

### –ì–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–∞—à –∞–ª–≥–æ—Ä–∏—Ç–º

```
src/models/group_shuffle/
‚îú‚îÄ‚îÄ layers.py        ‚Üê GroupShuffleLayer (–æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è)
‚îú‚îÄ‚îÄ model.py         ‚Üê GroupShuffleGNN (–æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å)
‚îî‚îÄ‚îÄ utils.py         ‚Üê –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
```

### –ì–¥–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è 6 baseline –º–µ—Ç–æ–¥–æ–≤

```
src/models/baselines/
‚îú‚îÄ‚îÄ bpr_mf.py       ‚Üê Baseline 1
‚îú‚îÄ‚îÄ lightgcn.py     ‚Üê Baseline 2 (—Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π!)
‚îú‚îÄ‚îÄ gcnii.py        ‚Üê Baseline 3
‚îú‚îÄ‚îÄ dgr.py          ‚Üê Baseline 4
‚îú‚îÄ‚îÄ svd_gcn.py      ‚Üê Baseline 5
‚îî‚îÄ‚îÄ layergcn.py     ‚Üê Baseline 6
```

### –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã

```
tests/
‚îú‚îÄ‚îÄ test_data.py           ‚Üê –¢–µ—Å—Ç—ã data pipeline
‚îú‚îÄ‚îÄ test_models.py         ‚Üê ‚≠ê –¢–µ—Å—Ç –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô!)
‚îú‚îÄ‚îÄ test_training.py       ‚Üê –¢–µ—Å—Ç—ã –æ–±—É—á–µ–Ω–∏—è
‚îî‚îÄ‚îÄ test_evaluation.py     ‚Üê –¢–µ—Å—Ç—ã –º–µ—Ç—Ä–∏–∫
```

### –ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞

`scripts/run_experiments.py` ‚Üê –ó–∞–ø—É—Å–∫–∞–µ—Ç –í–°–Å (–≤—Å–µ –º–æ–¥–µ–ª–∏, –≤—Å–µ –¥–∞—Ç–∞—Å–µ—Ç—ã)



---

## üéØ –ö–ê–ö –≠–¢–û –†–ê–ë–û–¢–ê–ï–¢ (–ü–û–®–ê–ì–û–í–û)

### –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–ø—É—Å–∫–∞–µ—Ç:

```bash
python scripts/run_experiments.py
```

### –°–∫—Ä–∏–ø—Ç –¥–µ–ª–∞–µ—Ç:

1. **–ó–∞–≥—Ä—É–∂–∞–µ—Ç 4 –¥–∞—Ç–∞—Å–µ—Ç–∞** (MovieLens, Yelp, Amazon, Gowalla)
2. **–î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞**:
   - –û–±—É—á–∞–µ—Ç 7 –º–æ–¥–µ–ª–µ–π (6 baseline + –≤–∞—à GroupShuffleGNN)
   - –ö–∞–∂–¥—É—é –º–æ–¥–µ–ª—å –∑–∞–ø—É—Å–∫–∞–µ—Ç 5 —Ä–∞–∑ (—Ä–∞–∑–Ω—ã–µ seeds)
   - –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
3. **–î–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏**:
   - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ‚Üí –û–±—É—á–µ–Ω–∏–µ ‚Üí –í–∞–ª–∏–¥–∞—Ü–∏—è ‚Üí –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
   - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
   - –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
4. **–ü–æ—Å–ª–µ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤**:
   - –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (mean ¬± std)
   - –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã (t-test)
   - –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è (–≥—Ä–∞—Ñ–∏–∫–∏, —Ç–∞–±–ª–∏—Ü—ã)

---

# üìã –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ü–†–û–ï–ö–¢–ê

## üîç –ß–¢–û –û–ü–ò–°–ê–ù–û –í –§–ê–ô–õ–ï

### 1. –ù–∞—É—á–Ω–∞—è –æ—Å–Ω–æ–≤–∞

- **–ú–µ—Ç–æ–¥**: Group and Shuffle –∏–∑ —Å—Ç–∞—Ç—å–∏ Gorbunov and Yudin
- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ**: –ë–æ—Ä—å–±–∞ —Å over-smoothing –≤ GNN —á–µ—Ä–µ–∑ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
- **–ù–æ–≤–∏–∑–Ω–∞**: –ü–µ—Ä–≤–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–∞ –∫ –∑–∞–¥–∞—á–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –≥—Ä–∞—Ñ–∞—Ö

### 2. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞

- **–î–∞—Ç–∞—Å–µ—Ç—ã**: 3-4 –¥–∞—Ç–∞—Å–µ—Ç–∞ (Movielens, Amazon-Book, + –µ—â–µ –æ–¥–∏–Ω)
- **Baseline –º–µ—Ç–æ–¥—ã**: 6 –º–µ—Ç–æ–¥–æ–≤ (BPR-MF, LightGCN, GCNII, DGR, SVD-GCN, LayerGCN)
- **–ú–µ—Ç—Ä–∏–∫–∏**: Recall@K, NDCG@K, Coverage, –º–µ—Ç—Ä–∏–∫–∏ over-smoothing
- **–ú–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è**: 5 –∑–∞–ø—É—Å–∫–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ seeds, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã

### 3. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã

- **–ú–æ–¥—É–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞**: –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ data, models, training, evaluation
- **–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å**: BaseRecommender –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
- **–í–∞—à –∞–ª–≥–æ—Ä–∏—Ç–º**: GroupShuffleGNN —Å GroupShuffleLayer
- **–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ**: Unit-—Ç–µ—Å—Ç—ã –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤

### 4. –ü–æ—Ç–æ–∫ —Ä–∞–±–æ—Ç—ã

1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–∑–∞–≥—Ä—É–∑–∫–∞, –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥, –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞)
2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π (6 baseline + –≤–∞—à –∞–ª–≥–æ—Ä–∏—Ç–º)
3. –û–±—É—á–µ–Ω–∏–µ (BPR loss, early stopping, –≤–∞–ª–∏–¥–∞—Ü–∏—è)
4. –û—Ü–µ–Ω–∫–∞ (–º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ over-smoothing)
5. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã (depth analysis, ablation studies)

---

## ‚úÖ –ß–¢–û –ù–£–ñ–ù–û –ë–£–î–ï–¢ –°–î–ï–õ–ê–¢–¨

### –≠—Ç–∞–ø 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã (1-2 –Ω–µ–¥–µ–ª–∏)

#### 1.1 –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è
- [ ] –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Python 3.8+
- [ ] –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (PyTorch, PyG, NumPy, Pandas, etc.)
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Å–∏—Å—Ç–µ–º—É –≤–µ—Ä—Å–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏—è (Git)

#### 1.2 –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
- [ ] –°–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
- [ ] –°–æ–∑–¥–∞—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (YAML)
- [ ] –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] –°–æ–∑–¥–∞—Ç—å –±–∞–∑–æ–≤—ã–µ –∫–ª–∞—Å—Å—ã (BaseRecommender)

### –≠—Ç–∞–ø 2: Data Pipeline (1 –Ω–µ–¥–µ–ª—è)

#### 2.1 –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `RecommendationDataset` –∫–ª–∞—Å—Å
- [ ] –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç—ã (Movielens, Amazon-Book, + —Ç—Ä–µ—Ç–∏–π)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é (min 10 interactions)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—é (implicit feedback)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (train/valid/test)

#### 2.2 –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ bipartite –≥—Ä–∞—Ñ–∞
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é adjacency matrix
- [ ] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ .npz

#### 2.3 –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] –¢–µ—Å—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
- [ ] –¢–µ—Å—Ç—ã –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞
- [ ] –¢–µ—Å—Ç—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
- [ ] –¢–µ—Å—Ç—ã –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∞

### –≠—Ç–∞–ø 3: Baseline –º–µ—Ç–æ–¥—ã (3-4 –Ω–µ–¥–µ–ª–∏)

#### 3.1 –ü—Ä–æ—Å—Ç—ã–µ –º–µ—Ç–æ–¥—ã (1 –Ω–µ–¥–µ–ª—è)
- [ ] **BPR-MF** (1 –¥–µ–Ω—å) - –±–∞–∑–æ–≤—ã–π –º–µ—Ç–æ–¥ –º–∞—Ç—Ä–∏—á–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
- [ ] **LightGCN** (3-4 –¥–Ω—è) - —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π baseline

#### 3.2 –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç–æ–¥—ã (1-2 –Ω–µ–¥–µ–ª–∏)
- [ ] **GCNII** (3-4 –¥–Ω—è) - residual connections
- [ ] **SVD-GCN** (5 –¥–Ω–µ–π) - —Å–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥

#### 3.3 –°–ª–æ–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã (1 –Ω–µ–¥–µ–ª—è)
- [ ] **DGR** (3-4 –¥–Ω—è) - desmoothing framework
- [ ] **LayerGCN** (3-4 –¥–Ω—è) - layer-wise refinement

#### 3.4 –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] –¢–µ—Å—Ç—ã forward pass –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
- [ ] –¢–µ—Å—Ç—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
- [ ] –¢–µ—Å—Ç—ã —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π embeddings

### –≠—Ç–∞–ø 4: –í–∞—à –∞–ª–≥–æ—Ä–∏—Ç–º GroupShuffleGNN (2 –Ω–µ–¥–µ–ª–∏)

#### 4.1 –†–µ–∞–ª–∏–∑–∞—Ü–∏—è GroupShuffleLayer
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã (–±–ª–æ—á–Ω–æ-–¥–∏–∞–≥–æ–Ω–∞–ª—å–Ω–∞—è)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å skew-symmetric –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏—é
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å exponential map (Lie group)
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å shuffle permutation
- [ ] **–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –¢–ï–°–¢**: –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –º–∞—Ç—Ä–∏—Ü—ã

#### 4.2 –†–µ–∞–ª–∏–∑–∞—Ü–∏—è GroupShuffleGNN
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å residual connections
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å layer aggregation
- [ ] –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å BaseRecommender

#### 4.3 –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] –¢–µ—Å—Ç –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!)
- [ ] –¢–µ—Å—Ç forward pass
- [ ] –¢–µ—Å—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞
- [ ] –¢–µ—Å—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π

### –≠—Ç–∞–ø 5: Training –∏ Evaluation (1 –Ω–µ–¥–µ–ª—è)

#### 5.1 Training
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å BPR Loss
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Trainer –∫–ª–∞—Å—Å
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å early stopping
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å checkpoint management
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –±–∞—Ç—á–∏–Ω–≥ –∏ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ

#### 5.2 Evaluation
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Recall@K
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å NDCG@K
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Coverage
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å OversmoothingAnalyzer
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ over-smoothing (cosine similarity, MAD)

#### 5.3 –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
- [ ] –¢–µ—Å—Ç—ã BPR Loss
- [ ] –¢–µ—Å—Ç—ã –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏ –æ–±—É—á–µ–Ω–∏—è
- [ ] –¢–µ—Å—Ç—ã early stopping
- [ ] –¢–µ—Å—Ç—ã –º–µ—Ç—Ä–∏–∫ –æ—Ü–µ–Ω–∫–∏

### –≠—Ç–∞–ø 6: –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã (2 –Ω–µ–¥–µ–ª–∏)

#### 6.1 –û—Å–Ω–æ–≤–Ω—ã–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
- [ ] –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å `run_experiments.py`
- [ ] –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö
- [ ] 5 –∑–∞–ø—É—Å–∫–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ seeds –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
- [ ] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

#### 6.2 Depth Analysis
- [ ] –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –≥–ª—É–±–∏–Ω–æ–π 2, 4, 8, 16 —Å–ª–æ–µ–≤
- [ ] –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –≥–ª—É–±–∏–Ω—ã –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–æ –∏ over-smoothing

#### 6.3 Ablation Studies
- [ ] –ë–µ–∑ residual connections
- [ ] –ë–µ–∑ shuffle
- [ ] –ë–µ–∑ layer aggregation
- [ ] –†–∞–∑–Ω—ã–µ block_size

#### 6.4 –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
- [ ] –í—ã—á–∏—Å–ª–µ–Ω–∏–µ mean ¬± std
- [ ] –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã (t-test)
- [ ] –í—ã—á–∏—Å–ª–µ–Ω–∏–µ p-values

### –≠—Ç–∞–ø 7: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (1 –Ω–µ–¥–µ–ª—è)

#### 7.1 –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
- [ ] –ì—Ä–∞—Ñ–∏–∫–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
- [ ] –ì—Ä–∞—Ñ–∏–∫–∏ depth analysis
- [ ] –ì—Ä–∞—Ñ–∏–∫–∏ ablation studies
- [ ] –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è over-smoothing –º–µ—Ç—Ä–∏–∫

#### 7.2 –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
- [ ] –û–±–Ω–æ–≤–∏—Ç—å README
- [ ] –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∫–æ–¥–∞ (docstrings)
- [ ] –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ –∑–∞–ø—É—Å–∫—É
- [ ] –û–ø–∏—Å–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

---

## ‚ùì –í–û–ü–†–û–°–´ –î–õ–Ø –£–¢–û–ß–ù–ï–ù–ò–Ø

1. **–¢—Ä–µ—Ç–∏–π –¥–∞—Ç–∞—Å–µ—Ç**: –ö–∞–∫–æ–π –¥–∞—Ç–∞—Å–µ—Ç –±—É–¥–µ—Ç –≤—ã–±—Ä–∞–Ω? (Yelp2018 –∏–ª–∏ Gowalla?)

2. **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã Group & Shuffle**:
   - –ö–∞–∫–æ–π `block_size` –ø–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å?
   - –ö–∞–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ `residual_alpha`?
   - –°–∫–æ–ª—å–∫–æ —Å–ª–æ–µ–≤ –≤ –±–∞–∑–æ–≤–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏?

3. **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è**:
   - –ï—Å—Ç—å –ª–∏ –¥–æ—Å—Ç—É–ø –∫ GPU?
   - –ö–∞–∫–∏–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏/—Ä–µ—Å—É—Ä—Å–∞–º?
   - –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≤–µ—Ä—Å–∏—è–º –±–∏–±–ª–∏–æ—Ç–µ–∫?

4. **–ú–µ—Ç—Ä–∏–∫–∏ over-smoothing**:
   - –ö–∞–∫–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è?
   - –ö–∞–∫ –±—É–¥–µ—Ç –∏–∑–º–µ—Ä—è—Ç—å—Å—è —Å—Ç–µ–ø–µ–Ω—å over-smoothing?

5. **–¢–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∞—è —á–∞—Å—Ç—å**:
   - –ü–ª–∞–Ω–∏—Ä—É–µ—Ç—Å—è –ª–∏ –¥–æ–±–∞–≤–ª—è—Ç—å —Ç–µ–æ—Ä–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞?
   - –ù—É–∂–Ω—ã –ª–∏ —Ç–µ–æ—Ä–µ–º—ã –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –Ω–æ—Ä–º/—É–≥–ª–æ–≤?

---

## üìä –û–¶–ï–ù–ö–ê –°–õ–û–ñ–ù–û–°–¢–ò –ò –í–†–ï–ú–ï–ù–ò

| –≠—Ç–∞–ø | –í—Ä–µ–º—è | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç |
|------|-------|-----------|-----------|
| –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ | 1-2 –Ω–µ–¥–µ–ª–∏ | ‚≠ê‚≠ê | –í—ã—Å–æ–∫–∏–π |
| Data Pipeline | 1 –Ω–µ–¥–µ–ª—è | ‚≠ê‚≠ê | –í—ã—Å–æ–∫–∏–π |
| Baseline –º–µ—Ç–æ–¥—ã | 3-4 –Ω–µ–¥–µ–ª–∏ | ‚≠ê‚≠ê‚≠ê | –í—ã—Å–æ–∫–∏–π |
| GroupShuffleGNN | 2 –Ω–µ–¥–µ–ª–∏ | ‚≠ê‚≠ê‚≠ê | –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π |
| Training/Eval | 1 –Ω–µ–¥–µ–ª—è | ‚≠ê‚≠ê | –í—ã—Å–æ–∫–∏–π |
| –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã | 2 –Ω–µ–¥–µ–ª–∏ | ‚≠ê‚≠ê | –í—ã—Å–æ–∫–∏–π |
| –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è | 1 –Ω–µ–¥–µ–ª—è | ‚≠ê | –°—Ä–µ–¥–Ω–∏–π |
| **–ò–¢–û–ì–û** | **~4 –º–µ—Å—è—Ü–∞** | | |

---

## üéØ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ú–û–ú–ï–ù–¢–´

1. **–¢–µ—Å—Ç –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏** - –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –º–µ—Ç–æ–¥–∞
2. **LightGCN** - —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π baseline, –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –ø–µ—Ä–≤—ã–º
3. **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã** - –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã –¥–ª—è –Ω–∞—É—á–Ω–æ–π –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏
4. **5 –∑–∞–ø—É—Å–∫–æ–≤ —Å —Ä–∞–∑–Ω—ã–º–∏ seeds** - –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
5. **Over-smoothing –º–µ—Ç—Ä–∏–∫–∏** - –∫–ª—é—á–µ–≤–∞—è —á–∞—Å—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è

---

## ‚úÖ –ß–ï–ö–õ–ò–°–¢ –ì–û–¢–û–í–ù–û–°–¢–ò –ö –†–ï–ê–õ–ò–ó–ê–¶–ò–ò

- [ ] –í—Å–µ –≤–æ–ø—Ä–æ—Å—ã —É—Ç–æ—á–Ω–µ–Ω—ã
- [ ] –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞ –ø–æ–Ω—è—Ç–Ω–∞
- [ ] Baseline –º–µ—Ç–æ–¥—ã –≤—ã–±—Ä–∞–Ω—ã –∏ –∏–∑—É—á–µ–Ω—ã
- [ ] –ú–µ—Ç–æ–¥ Group & Shuffle –∏–∑—É—á–µ–Ω
- [ ] –î–∞—Ç–∞—Å–µ—Ç—ã –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –∏–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
- [ ] –û–∫—Ä—É–∂–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ
- [ ] –ü–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω


