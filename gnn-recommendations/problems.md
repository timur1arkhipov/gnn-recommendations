## 1 встреча:
1) (orthogonal_bundle) Схема обучения эмбеддингов определена и зафиксирована:
   - user/item embeddings — обучаемые параметры модели.
   - Инициализация по умолчанию: случайная N(0, 0.01).
   - Основное обучение: end-to-end через BPR Loss (user/item embeddings + матрицы переноса + локальные трансформации оптимизируются совместно).
   - warm-start от LightGCN (как отдельный режим):
     1) обучить LightGCN на том же датасете,
     2) экспортировать user/item embeddings,
     3) загрузить embeddings в OrthogonalBundle и дообучить всю модель.
   - Для пользователей отсутствие признаков не проблема: их embeddings обучаются через взаимодействия (как в стандартных CF-моделях).
   команды:
   - python c:\Users\timur\OneDrive\Документы\diploma\gnn-recommendations\scripts\run_all_experiments.py --models lightgcn --datasets movie_lens --seed 42

   - python c:\Users\timur\OneDrive\Документы\diploma\gnn-recommendations\scripts\run_all_experiments.py --models orthogonal_bundle --datasets movie_lens --seed 42

1.2) LightGCN
   - Инициализация: обучаемые эмбеддинги пользователей и айтемов.
   - Графовая свёртка L раз: x <- A_norm * x (без нелинейностей и весов).
   - Layer aggregation: усреднение embeddings со всех слоёв (включая слой 0).
   - Скоринг: скалярное произведение user_emb и item_emb.
   - Обучение: BPR Loss, всё end‑to‑end.

2) (orthogonal_bundle) Архитектура формализована (вариант A, shared connection):
   - Соединительная матрица W^(l) зависит только от слоя l и является общей для всех рёбер.
   - W^(l) ортогональна и реализует общий transport между fiber spaces, что соответствует идее vector bundles.
   - Связь не зависит от конкретного ребра или эмбеддингов узлов → единые правила переноса по всему графу.
   - Формула слоя фиксируется явно:
     x^(l+1) = (1-α) · GS( PT(x^(l), W^(l)) ) + α · x^(0)
        x^(l) — эмбеддинги узлов на слое l.
        x^(0) — исходные (начальные) эмбеддинги (до всех слоёв).
        PT(·, W^(l)) — parallel transport: перенос информации от соседей с помощью ортогональной матрицы связи W^(l).
        W^(l) — общая ортогональная матрица для слоя l (shared для всех рёбер).
        GS(·) — Group & Shuffle: локальная ортогональная трансформация внутри fiber space (перемешивание/поворот признаков, без изменения нормы).
        α — коэффициент residual‑смешивания (обычно небольшой, например 0.1).
   - Число параметров считается прозрачно: embeddings + набор W^(l) + локальные ортогональные преобразования,
     и сравнивается с бейзлайнами.

3) (orthogonal_bundle) Валидация корректности: вводится runtime-метрика ортогональности.
   - На каждом N‑м шаге/эпохе логируется ||QᵀQ − I||_F для всех ортогональных матриц слоя.
   - Пороговая интерпретация: чем ближе к 0, тем лучше соблюдена ортогональность.
   - Дополнительно можно логировать max‑deviation по слоям (max |(QᵀQ − I)_ij|) для контроля численной стабильности.
   - Расшифровка строки лога:
     Orthogonality (lower is better) — все показатели ниже, если матрицы ближе к ортогональным.
     FroErr(local) — средняя ошибка ||QᵀQ − I||_F для локальных GS‑матриц.
     FroErr(conn) — средняя ошибка ||QᵀQ − I||_F для connection‑матриц W^(l).
     MaxDev(local) — максимальное по модулю отклонение элемента (QᵀQ − I) для GS.
     MaxDev(conn) — максимальное по модулю отклонение элемента (QᵀQ − I) для W^(l).
     Grade — качественная оценка по FroErr (меньше → лучше): совсем не ортогональные / слабая ортогональность / почти ортогональные / точно ортогональные.

4) методологические проблемы с экспериментами и сравнением. Пока модель не доведена до стабильной версии, сравнение с бейзлайнами некорректно. Неясно, как сравнивать модели в «равных условиях», если используется прогрев эмбеддингов или дополнительное предварительное обучение. Нет четкого плана: что является частью модели, а что — вспомогательной процедурой.

Вопросы:
1) если у меня датасеты explicit и implicit, но я по сути привожу их к implicit (рейтинг >= 4 = 1, рейтинг < 4 = 0), насколько это верно? м.б. стоит другой способ подобрать?
2) как верно будет сравнивать модели особенно при учете что в orthogonal bundle есть warm-up с light gcn ?
3) деление дата сета random per-user сейчас, нормальный ли это подход?
4) по проведению экспериментов, сейчас 3-datasets, 6 baselines + orthogonal bundle, 5 seeds и 10 метрик, хватит ли это?
5) вот проблема с размером датасета, на примере movielens, какой минимуальный размер?

## 2 встреча
1) Архитектура и сравнение с LightGCN
– LightGCN можно рассматривать как базовую архитектуру для прогрева эмбеддингов.
– Корректный подход: сначала обучить модель как LightGCN (без дополнительных преобразований), затем в той же архитектуре заменить свёртку/месседж-пассинг на свою.
– Размерности слоёв и полносвязные слои не менять, чтобы сравнение было честным.
– Эмбеддинги можно замораживать или дообучать; даже на замороженных ожидается улучшение.
– Сравнение «одна и та же архитектура + разная свёртка» считается корректным.

2) Стратегия по бейзлайнам:
Не фиксировать параметры, а максимизировать метрику при доступных ресурсах.
– Для диплома допустимо ориентироваться на метрики из статей, а не обязательно полностью воспроизводить чужой код.
– Желательно брать датасеты и постановку (split, метрики), используемые в релевантных статьях.

3) Датасеты
– Малые датасеты (например, MovieLens 100k) подходят только для отладки пайплайна.
– Для реальных сравнений лучше брать крупные датасеты, иначе простые методы (SVD) могут выглядеть лучше нейросетей.
– Лучше использовать те же датасеты, что и в статьях, с которыми идёт сравнение (MovieLens 100K/1M/, Facebook, Amazon Books).

4) Train / test split - скопировать из sheaf статьи для верного сравнения.
Датасеты
  В репозитории используются 5 датасетов (dataset.py:22-42):        
                                                                    
  1. MovieLens 100K (ml-100k)                                       
    - Файл: data/ml-100k/u.data                                     
    - Формат: user_id, item_id, rating, timestamp (разделитель TAB) 
  2. MovieLens 1M (ml-1m)                                           
    - Файл: data/ml-1m/ratings.dat                                  
    - Формат: user_id, item_id, rating, timestamp (разделитель ::)  
  3. Amazon Books (amazon)                                          
    - Файл: data/Books_rating.csv                                   
    - Формат: user_id, item_id, rating, timestamp (разделитель TAB) 
  4. Facebook (facebook)                                            
    - Файл: data/dataset_facebook.tsv                               
    - Формат: user_id, item_id, rating (разделитель TAB, без        
  timestamp)                                                        
                                                                    
  Предобработка: фильтрация рейтингов >= 3 (кроме Facebook),        
  построение двудольного графа пользователь-айтем.                  
                                                                    
  Разбиение на Train/Val/Test                                       
  Train: 80% | Validation: 10% | Test: 10%                          
                                                                    
  Процесс:                                                          
  1. Первое разбиение: 80% train, 20% temp_test (random_state=seed) 
  2. Второе разбиение: 10% validation, 10% test из temp_test        
  3. Фильтрация: val и test содержат только пользователей и айтемы  
  из train (трансдуктивная оценка)                                  
  4. Перемаркировка: user_id и item_id перекодируются в непрерывные
  индексы через LabelEncoder

### 1. Датасеты
- MovieLens 100K (ml-100k) для тестов пайплайна
- MovieLens 1M (ml-1m)
- Amazon Books (amazon_books)
- Facebook (facebook)

### 2. Предобработка
- Фильтрация рейтингов >= 3 (кроме Facebook)
- Построение двудольного графа пользователь-айтем

### 3. Разбиение Train/Val/Test (80-10-10)
- Первое разбиение: 80% train, 20% temp_test
- Второе разбиение: 10% validation, 10% test
- Трансдуктивная фильтрация (val/test содержат только пользователей и айтемы из train)
- Перемаркировка ID через LabelEncoder

Единый формат после загрузки
Все загрузчики наследуются от `BaseDatasetLoader` и преобразуют данные в единый формат:
Обязательные поля:
- `userId` (int) - ID пользователя
- `itemId` (int) - ID айтема

Опциональные поля:
- `rating` (float) - рейтинг взаимодействия (используется для бинаризации)
- `timestamp` (int) - временная метка (используется для temporal split)

- ml-100k: rating >= 3.0 → положительное взаимодействие
- ml-1m: rating >= 3.0 → положительное взаимодействие
- amazon_books: rating >= 3.0 → положительное взаимодействие
- facebook: rating >= 0.0 → все взаимодействия положительные (implicit)

Поля по бизнес-логике (при сборе данных)
1. После загрузки (load_raw_data):
- `userId` - исходный ID пользователя (может быть int/str, не обязательно последовательный)
- `itemId` - исходный ID айтема (может быть int/str, не обязательно последовательный)
- `rating` - исходный рейтинг (1-5 для explicit, 0-1 для implicit, может быть None)
- `timestamp` - временная метка (опционально)

2. После бинаризации (binarize_interactions):
- `userId` - исходный ID пользователя
- `itemId` - исходный ID айтема
- `rating` колонка удалена - теперь все оставшиеся строки = положительные взаимодействия

3. После фильтрации (filter_by_min_interactions):
- `userId` - исходный ID пользователя (только активные пользователи с >= min взаимодействиями)
- `itemId` - исходный ID айтема (только популярные айтемы с >= min взаимодействиями)

4. После нормализации ID (normalize_ids):
- `userId` - перекодированный ID (0, 1, 2, ..., n_users-1)
- `itemId` - перекодированный ID (0, 1, 2, ..., n_items-1)
- Маппинги: old_id → new_id сохраняются отдельно

5. После split (train/valid/test):
Те же поля, но разделенные на 3 множества с трансдуктивной фильтрацией

6. В графе (adj_matrix):
- Индексы узлов: [0...n_users-1] = пользователи, [n_users...n_users+n_items-1] = айтемы
- Значения: 1 = есть ребро (взаимодействие), 0 = нет ребра