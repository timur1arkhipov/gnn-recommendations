# –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –º–æ–¥–µ–ª—è–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º

## üìã –û–±–∑–æ—Ä

–í –ø—Ä–æ–µ–∫—Ç–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ **7 –º–æ–¥–µ–ª–µ–π** –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º:
- **6 baseline –º–æ–¥–µ–ª–µ–π** –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
- **1 –≤–∞—à–∞ –º–æ–¥–µ–ª—å** (GroupShuffleGNN)

–í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–∞—Å–ª–µ–¥—É—é—Ç—Å—è –æ—Ç `BaseRecommender` –∏ –∏–º–µ—é—Ç **–µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å**.

---

## üéØ –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç

### –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª—é–±—É—é –º–æ–¥–µ–ª—å

```python
from models import LightGCN  # –∏–ª–∏ –ª—é–±–∞—è –¥—Ä—É–≥–∞—è –º–æ–¥–µ–ª—å
from data import RecommendationDataset

# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
dataset = RecommendationDataset(name="movie_lens")
dataset.load_processed_data()
adj_matrix = dataset.get_torch_adjacency(normalized=True)

# 2. –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
model = LightGCN(
    n_users=dataset.n_users,
    n_items=dataset.n_items,
    embedding_dim=64,
    n_layers=3
)

# 3. Forward pass
user_emb, item_emb = model(adj_matrix)

# 4. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
scores = model.predict(users, items, adj_matrix)
```

**–í—Å–µ –º–æ–¥–µ–ª–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤–æ!** –†–∞–∑–ª–∏—á–∏—è —Ç–æ–ª—å–∫–æ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.

---

## üèóÔ∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–µ–π

### –û–±—â–∏–π –ø—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï                             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  - n_users: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π                    ‚îÇ
‚îÇ  - n_items: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–π—Ç–µ–º–æ–≤                          ‚îÇ
‚îÇ  - adj_matrix: normalized adjacency matrix [N, N]       ‚îÇ
‚îÇ    –≥–¥–µ N = n_users + n_items                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   –ù–ê–ß–ê–õ–¨–ù–´–ï EMBEDDINGS         ‚îÇ
        ‚îÇ   user_embedding: [n_users, d] ‚îÇ
        ‚îÇ   item_embedding: [n_items, d] ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   –ú–û–î–ï–õ–¨-–°–ü–ï–¶–ò–§–ò–ß–ù–ê–Ø          ‚îÇ
        ‚îÇ   –û–ë–†–ê–ë–û–¢–ö–ê                    ‚îÇ
        ‚îÇ   (–≥—Ä–∞—Ñ–æ–≤–∞—è —Å–≤–µ—Ä—Ç–∫–∞,           ‚îÇ
        ‚îÇ    —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∏ —Ç.–¥.)      ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   –§–ò–ù–ê–õ–¨–ù–´–ï EMBEDDINGS        ‚îÇ
        ‚îÇ   user_emb: [n_users, d]      ‚îÇ
        ‚îÇ   item_emb: [n_items, d]      ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ   –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï SCORES         ‚îÇ
        ‚îÇ   score = user_emb @ item_emb ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

### 1. BPR-MF (Bayesian Personalized Ranking - Matrix Factorization)

**–§–∞–π–ª:** `baselines/bpr_mf.py`

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
–ù–∞—á–∞–ª—å–Ω—ã–µ embeddings
    ‚Üì
[user_embedding] [item_embedding]
    ‚Üì              ‚Üì
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
    –°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ
           ‚Üì
    scores = user_emb ¬∑ item_emb
```

#### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **–°–∞–º–∞—è –ø—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å** - —Ç–æ–ª—å–∫–æ embeddings, –±–µ–∑ –≥—Ä–∞—Ñ–æ–≤–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
- **–ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç adj_matrix** - —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å embeddings
- **–ë—ã—Å—Ç—Ä–∞—è** - –º–∏–Ω–∏–º—É–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- **–ë–∞–∑–æ–≤—ã–π baseline** - –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏

#### –§–æ—Ä–º—É–ª–∞

```
score(u, i) = user_emb[u] ¬∑ item_emb[i]
```

#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

- `embedding_dim`: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 64)
- `init_scale`: –º–∞—Å—à—Ç–∞–± –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.01)

#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from models import BPR_MF

model = BPR_MF(n_users=1000, n_items=2000, embedding_dim=64)

# Forward (adj_matrix –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
user_emb, item_emb = model()  # –∏–ª–∏ model(None)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
scores = model.predict(users, items)
```

---

### 2. LightGCN (Light Graph Convolutional Network)

**–§–∞–π–ª:** `baselines/lightgcn.py`

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
–ù–∞—á–∞–ª—å–Ω—ã–µ embeddings
    ‚Üì
x‚ÇÄ = [user_emb, item_emb]
    ‚Üì
–ì—Ä–∞—Ñ–æ–≤–∞—è —Å–≤–µ—Ä—Ç–∫–∞ (—Å–ª–æ–π 1)
    ‚Üì
x‚ÇÅ = A @ x‚ÇÄ
    ‚Üì
–ì—Ä–∞—Ñ–æ–≤–∞—è —Å–≤–µ—Ä—Ç–∫–∞ (—Å–ª–æ–π 2)
    ‚Üì
x‚ÇÇ = A @ x‚ÇÅ
    ‚Üì
... (n_layers —Ä–∞–∑)
    ‚Üì
Layer Aggregation
    ‚Üì
x_final = mean([x‚ÇÄ, x‚ÇÅ, x‚ÇÇ, ..., x‚Çô])
```

#### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π GCN** - —É–±—Ä–∞–Ω—ã –Ω–µ–ª–∏–Ω–µ–π–Ω–æ—Å—Ç–∏ –∏ –≤–µ—Å–∞
- **–¢–æ–ª—å–∫–æ –≥—Ä–∞—Ñ–æ–≤–∞—è —Å–≤–µ—Ä—Ç–∫–∞** - A @ x –Ω–∞ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ
- **Layer aggregation** - —Å—Ä–µ–¥–Ω–µ–µ –≤—Å–µ—Ö —Å–ª–æ–µ–≤
- **–û—á–µ–Ω—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π** - –æ–¥–∏–Ω –∏–∑ –ª—É—á—à–∏—Ö baseline –º–µ—Ç–æ–¥–æ–≤

#### –§–æ—Ä–º—É–ª–∞

```
x^(l+1) = A @ x^(l)
x_final = mean([x^(0), x^(1), ..., x^(L)])
```

–≥–¥–µ:
- `A` - normalized adjacency matrix
- `x^(l)` - embeddings –Ω–∞ —Å–ª–æ–µ l
- `L` - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤

#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

- `embedding_dim`: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings (64)
- `n_layers`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ (3)
- `init_scale`: –º–∞—Å—à—Ç–∞–± –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (0.01)

#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from models import LightGCN

model = LightGCN(
    n_users=1000,
    n_items=2000,
    embedding_dim=64,
    n_layers=3
)

# Forward (—Ç—Ä–µ–±—É–µ—Ç adj_matrix)
user_emb, item_emb = model(adj_matrix)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
scores = model.predict(users, items, adj_matrix)
```

---

### 3. GCNII (Graph Convolutional Network with Initial residual and Identity mapping)

**–§–∞–π–ª:** `baselines/gcnii.py`

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
–ù–∞—á–∞–ª—å–Ω—ã–µ embeddings
    ‚Üì
x‚ÇÄ = [user_emb, item_emb]
    ‚Üì
–°–ª–æ–π 1:
  x_conv = A @ x‚ÇÄ
  x_transformed = x_conv @ W‚ÇÅ
  x‚ÇÅ = (1-Œ±) ¬∑ x_transformed + Œ± ¬∑ x‚ÇÄ  (identity mapping)
    ‚Üì
–°–ª–æ–π 2:
  x_conv = A @ x‚ÇÅ
  x_transformed = x_conv @ W‚ÇÇ
  x‚ÇÇ = (1-Œ±) ¬∑ x_transformed + Œ± ¬∑ x‚ÇÄ  (identity mapping)
  x‚ÇÇ = (1-Œ≤) ¬∑ x‚ÇÇ + Œ≤ ¬∑ x‚ÇÅ  (residual connection)
    ‚Üì
... (n_layers —Ä–∞–∑)
```

#### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **Residual connections** - —Å–≤—è–∑—å –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Å–ª–æ—è–º–∏
- **Identity mapping** - —Å–≤—è–∑—å —Å –Ω–∞—á–∞–ª—å–Ω—ã–º–∏ embeddings
- **–ë–æ—Ä—å–±–∞ —Å over-smoothing** - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –Ω–∞—á–∞–ª—å–Ω—ã—Ö —Å–ª–æ–µ–≤
- **–í–µ—Å–∞ –Ω–∞ –∫–∞–∂–¥–æ–º —Å–ª–æ–µ** - –ª–∏–Ω–µ–π–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è

#### –§–æ—Ä–º—É–ª–∞

```
x^(l+1) = (1 - Œ±) ¬∑ (A @ x^(l) @ W^(l)) + Œ± ¬∑ x^(0)  (identity)
x^(l+1) = (1 - Œ≤) ¬∑ x^(l+1) + Œ≤ ¬∑ x^(l)  (residual, –µ—Å–ª–∏ l > 0)
```

–≥–¥–µ:
- `Œ±` - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç identity mapping (0.1)
- `Œ≤` - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç residual connection (0.5)
- `W^(l)` - –≤–µ—Å–∞ —Å–ª–æ—è l

#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

- `embedding_dim`: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings (64)
- `n_layers`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ (3)
- `alpha`: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç identity mapping (0.1)
- `beta`: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç residual connection (0.5)
- `dropout`: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å dropout (0.0)

#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from models import GCNII

model = GCNII(
    n_users=1000,
    n_items=2000,
    embedding_dim=64,
    n_layers=3,
    alpha=0.1,
    beta=0.5
)

user_emb, item_emb = model(adj_matrix)
scores = model.predict(users, items, adj_matrix)
```

---

### 4. DGR (Desmoothing Graph Representation)

**–§–∞–π–ª:** `baselines/dgr.py`

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
–ù–∞—á–∞–ª—å–Ω—ã–µ embeddings
    ‚Üì
x‚ÇÄ = [user_emb, item_emb]
    ‚Üì
–°–ª–æ–π 1:
  x_conv = A @ x‚ÇÄ
  x_transformed = x_conv @ W‚ÇÅ
  x‚ÇÅ = (1-Œª) ¬∑ x_transformed + Œª ¬∑ x‚ÇÄ  (desmoothing)
    ‚Üì
–°–ª–æ–π 2:
  x_conv = A @ x‚ÇÅ
  x_transformed = x_conv @ W‚ÇÇ
  x‚ÇÇ = (1-Œª) ¬∑ x_transformed + Œª ¬∑ x‚ÇÅ  (desmoothing)
    ‚Üì
... (n_layers —Ä–∞–∑)
```

#### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **Desmoothing framework** - –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ over-smoothing
- **–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è** - –∫–æ–º–±–∏–Ω–∞—Ü–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∏ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–ª–æ—è
- **–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥** (2024)
- **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π**

#### –§–æ—Ä–º—É–ª–∞

```
x^(l+1) = (1 - Œª) ¬∑ (A @ x^(l) @ W^(l)) + Œª ¬∑ x^(l)
```

–≥–¥–µ:
- `Œª` - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ (0.1)

#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

- `embedding_dim`: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings (64)
- `n_layers`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ (3)
- `lambda_reg`: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ (0.1)
- `dropout`: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å dropout (0.0)

#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from models import DGR

model = DGR(
    n_users=1000,
    n_items=2000,
    embedding_dim=64,
    n_layers=3,
    lambda_reg=0.1
)

user_emb, item_emb = model(adj_matrix)
scores = model.predict(users, items, adj_matrix)
```

---

### 5. SVD-GCN (SVD Graph Convolutional Network)

**–§–∞–π–ª:** `baselines/svd_gcn.py`

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
–ù–∞—á–∞–ª—å–Ω—ã–µ embeddings
    ‚Üì
SVD –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è A:
  A ‚âà U @ S @ V^T
  (–Ω–∏–∑–∫–æ—Ä–∞–Ω–≥–æ–≤–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ)
    ‚Üì
–°–ª–æ–π 1:
  x_conv = U @ (S ¬∑ (V^T @ x‚ÇÄ))  (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞)
  x‚ÇÅ = x_conv @ W‚ÇÅ
    ‚Üì
–°–ª–æ–π 2:
  x_conv = U @ (S ¬∑ (V^T @ x‚ÇÅ))
  x‚ÇÇ = x_conv @ W‚ÇÇ
    ‚Üì
... (n_layers —Ä–∞–∑)
```

#### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **SVD –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è** - –Ω–∏–∑–∫–æ—Ä–∞–Ω–≥–æ–≤–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ adjacency matrix
- **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å** - –º–µ–Ω—å—à–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –¥–ª—è –±–æ–ª—å—à–∏—Ö –≥—Ä–∞—Ñ–æ–≤
- **–°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥** - —Ä–∞–±–æ—Ç–∞ –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤
- **–†–∞–Ω–≥ –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç—Å—è** - –ø–∞—Ä–∞–º–µ—Ç—Ä `rank`

#### –§–æ—Ä–º—É–ª–∞

```
A ‚âà U @ diag(S) @ V^T  (SVD, rank = k)
x_conv = U @ (S ¬∑ (V^T @ x))
x^(l+1) = x_conv @ W^(l)
```

–≥–¥–µ:
- `U, S, V` - SVD –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
- `k` - —Ä–∞–Ω–≥ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏—è (rank)

#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

- `embedding_dim`: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings (64)
- `n_layers`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ (3)
- `rank`: —Ä–∞–Ω–≥ SVD (64, –æ–±—ã—á–Ω–æ = embedding_dim)
- `dropout`: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å dropout (0.0)

#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from models import SVD_GCN

model = SVD_GCN(
    n_users=1000,
    n_items=2000,
    embedding_dim=64,
    n_layers=3,
    rank=32  # –Ω–∏–∑–∫–æ—Ä–∞–Ω–≥–æ–≤–æ–µ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ
)

user_emb, item_emb = model(adj_matrix)
scores = model.predict(users, items, adj_matrix)
```

---

### 6. LayerGCN (Layer-wise Graph Convolutional Network)

**–§–∞–π–ª:** `baselines/layergcn.py`

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
–ù–∞—á–∞–ª—å–Ω—ã–µ embeddings
    ‚Üì
x‚ÇÄ = [user_emb, item_emb]
    ‚Üì
–°–ª–æ–π 1:
  x_conv = A @ x‚ÇÄ
  x_transformed = x_conv @ W‚ÇÅ
  x‚ÇÅ = Œ± ¬∑ x_transformed + (1-Œ±) ¬∑ x‚ÇÄ  (layer-wise refinement)
    ‚Üì
–°–ª–æ–π 2:
  x_conv = A @ x‚ÇÅ
  x_transformed = x_conv @ W‚ÇÇ
  prev_avg = mean([x‚ÇÄ, x‚ÇÅ])  (—Å—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–ª–æ–µ–≤)
  x‚ÇÇ = Œ± ¬∑ x_transformed + (1-Œ±) ¬∑ prev_avg
    ‚Üì
... (n_layers —Ä–∞–∑)
    ‚Üì
–§–∏–Ω–∞–ª—å–Ω–æ–µ: mean([x‚ÇÄ, x‚ÇÅ, ..., x‚Çô])
```

#### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **Layer-wise refinement** - –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ —É—Ç–æ—á–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π
- **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–ª–æ–µ–≤** - –∫–æ–º–±–∏–Ω–∞—Ü–∏—è —Å —Å—Ä–µ–¥–Ω–∏–º –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö
- **–§–∏–Ω–∞–ª—å–Ω–∞—è –∞–≥—Ä–µ–≥–∞—Ü–∏—è** - —Å—Ä–µ–¥–Ω–µ–µ –≤—Å–µ—Ö —Å–ª–æ–µ–≤
- **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–µ–Ω –¥–ª—è –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π**

#### –§–æ—Ä–º—É–ª–∞

```
x^(l+1) = Œ± ¬∑ (A @ x^(l) @ W^(l)) + (1-Œ±) ¬∑ mean([x^(0), ..., x^(l)])
x_final = mean([x^(0), x^(1), ..., x^(L)])
```

–≥–¥–µ:
- `Œ±` - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç layer-wise refinement (0.5)

#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

- `embedding_dim`: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings (64)
- `n_layers`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ (3)
- `alpha`: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç layer-wise refinement (0.5)
- `dropout`: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å dropout (0.0)

#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from models import LayerGCN

model = LayerGCN(
    n_users=1000,
    n_items=2000,
    embedding_dim=64,
    n_layers=3,
    alpha=0.5
)

user_emb, item_emb = model(adj_matrix)
scores = model.predict(users, items, adj_matrix)
```

---

### 7. GroupShuffleGNN ‚≠ê (–í–∞—à–∞ –º–æ–¥–µ–ª—å)

**–§–∞–π–ª:** `group_shuffle/model.py`

#### –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
–ù–∞—á–∞–ª—å–Ω—ã–µ embeddings
    ‚Üì
x‚ÇÄ = [user_emb, item_emb]
    ‚Üì
GroupShuffleLayer 1:
  1. Graph convolution: x_conv = A @ x‚ÇÄ
  2. Group (–æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ):
     W_orth = block_diag([exp(A_skew_1), ..., exp(A_skew_k)])
     x_transformed = x_conv @ W_orth
  3. Shuffle: x_shuffled = x_transformed[:, perm]
  4. Residual: x‚ÇÅ = (1-Œ±) ¬∑ x_shuffled + Œ± ¬∑ x‚ÇÄ
    ‚Üì
GroupShuffleLayer 2:
  (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ)
    ‚Üì
... (n_layers —Ä–∞–∑)
    ‚Üì
Layer Aggregation: mean([x‚ÇÄ, x‚ÇÅ, ..., x‚Çô])
```

#### –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

- **–û—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ** - —á–µ—Ä–µ–∑ exponential map (Lie group)
- **–ë–ª–æ—á–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞** - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏—è O(p√ón) –≤–º–µ—Å—Ç–æ O(n¬≤)
- **Shuffle** - –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
- **Residual connections** - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
- **Layer aggregation** - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–ª–æ–µ–≤

#### –§–æ—Ä–º—É–ª–∞

```
x_conv = A @ x
W_orth = block_diag([exp(A_skew_1), ..., exp(A_skew_k)])  (–æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–∞—è)
x_transformed = x_conv @ W_orth
x_shuffled = x_transformed[:, perm]
x^(l+1) = (1-Œ±) ¬∑ x_shuffled + Œ± ¬∑ x^(0)  (residual)
x_final = mean([x^(0), x^(1), ..., x^(L)])
```

–≥–¥–µ:
- `A_skew_i` - skew-symmetric –º–∞—Ç—Ä–∏—Ü—ã –¥–ª—è –±–ª–æ–∫–∞ i
- `exp(A_skew)` - exponential map (–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)
- `perm` - –ø–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–ª—è shuffle
- `Œ±` - –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç residual (0.1)

#### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã

- `embedding_dim`: —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å embeddings (64, –¥–æ–ª–∂–Ω–∞ –¥–µ–ª–∏—Ç—å—Å—è –Ω–∞ block_size)
- `n_layers`: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤ (3)
- `block_size`: —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ –¥–ª—è –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã (8)
- `residual_alpha`: –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç residual (0.1)
- `dropout`: –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å dropout (0.0)

#### –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from models import GroupShuffleGNN

model = GroupShuffleGNN(
    n_users=1000,
    n_items=2000,
    embedding_dim=64,
    n_layers=3,
    block_size=8,
    residual_alpha=0.1
)

user_emb, item_emb = model(adj_matrix)
scores = model.predict(users, items, adj_matrix)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
errors = model.get_orthogonality_errors()
```

---

## üîÑ –ö–∞–∫ –≤—Å–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Å–∏—Å—Ç–µ–º–µ

### –ü–æ–ª–Ω—ã–π pipeline —Ä–∞–±–æ—Ç—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  –≠–¢–ê–ü 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö                              ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  python scripts/prepare_data.py --dataset movie_lens   ‚îÇ
‚îÇ    ‚Üì                                                     ‚îÇ
‚îÇ  - –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö (—á–µ—Ä–µ–∑ loaders)                      ‚îÇ
‚îÇ  - –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ (—Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è, –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è)              ‚îÇ
‚îÇ  - –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/valid/test                       ‚îÇ
‚îÇ  - –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤ (bipartite graph)                  ‚îÇ
‚îÇ    ‚Üì                                                     ‚îÇ
‚îÇ  –†–µ–∑—É–ª—å—Ç–∞—Ç:                                              ‚îÇ
‚îÇ  - data/processed/{dataset}/train.txt, valid.txt, ...    ‚îÇ
‚îÇ  - data/graphs/{dataset}/norm_adj_matrix.npz            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  –≠–¢–ê–ü 2: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  from models import LightGCN                             ‚îÇ
‚îÇ  from data import RecommendationDataset                 ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ                        ‚îÇ
‚îÇ  dataset = RecommendationDataset(name="movie_lens")     ‚îÇ
‚îÇ  dataset.load_processed_data()                           ‚îÇ
‚îÇ  adj_matrix = dataset.get_torch_adjacency()              ‚îÇ
‚îÇ    # adj_matrix: [N, N] sparse tensor                   ‚îÇ
‚îÇ    # N = n_users + n_items                              ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å                                        ‚îÇ
‚îÇ  model = LightGCN(                                       ‚îÇ
‚îÇ      n_users=dataset.n_users,                            ‚îÇ
‚îÇ      n_items=dataset.n_items,                             ‚îÇ
‚îÇ      embedding_dim=64,                                   ‚îÇ
‚îÇ      n_layers=3                                          ‚îÇ
‚îÇ  )                                                       ‚îÇ
‚îÇ    ‚Üì                                                     ‚îÇ
‚îÇ  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è embeddings:                            ‚îÇ
‚îÇ  # user_embedding: [n_users, 64]                        ‚îÇ
‚îÇ  # item_embedding: [n_items, 64]                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  –≠–¢–ê–ü 3: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  trainer = Trainer(model, dataset, config)              ‚îÇ
‚îÇ  trainer.train()                                         ‚îÇ
‚îÇ    ‚Üì                                                     ‚îÇ
‚îÇ  –î–ª—è –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏:                                       ‚îÇ
‚îÇ    1. –°—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∞—Ç—á–µ–π:                              ‚îÇ
‚îÇ       - user: [batch_size]                               ‚îÇ
‚îÇ       - pos_item: [batch_size] (–∏–∑ train)                ‚îÇ
‚îÇ       - neg_item: [batch_size] (—Å–ª—É—á–∞–π–Ω—ã–µ)               ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ    2. Forward pass:                                      ‚îÇ
‚îÇ       user_emb, item_emb = model(adj_matrix)            ‚îÇ
‚îÇ       # user_emb: [n_users, 64]                         ‚îÇ
‚îÇ       # item_emb: [n_items, 64]                         ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ    3. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ scores:                                ‚îÇ
‚îÇ       pos_scores = (user_emb[users] * item_emb[pos_items]).sum(1)
‚îÇ       neg_scores = (user_emb[users] * item_emb[neg_items]).sum(1)
‚îÇ                                                          ‚îÇ
‚îÇ    4. BPR Loss:                                         ‚îÇ
‚îÇ       loss = -log(œÉ(pos_score - neg_score))             ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ    5. Backward + –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è:                           ‚îÇ
‚îÇ       loss.backward()                                    ‚îÇ
‚îÇ       optimizer.step()                                   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ    6. –í–∞–ª–∏–¥–∞—Ü–∏—è (–∫–∞–∂–¥—ã–µ N —ç–ø–æ—Ö):                        ‚îÇ
‚îÇ       metrics = evaluator.evaluate(model, valid_data)   ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ    7. Early stopping:                                   ‚îÇ
‚îÇ       –µ—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∞ –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è ‚Üí –æ—Å—Ç–∞–Ω–æ–≤–∫–∞            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  –≠–¢–ê–ü 4: –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  evaluator = Evaluator()                                 ‚îÇ
‚îÇ  metrics = evaluator.evaluate(model, dataset.test_data) ‚îÇ
‚îÇ    ‚Üì                                                     ‚îÇ
‚îÇ  –ü—Ä–æ—Ü–µ—Å—Å –æ—Ü–µ–Ω–∫–∏:                                         ‚îÇ
‚îÇ    1. –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ embeddings:                          ‚îÇ
‚îÇ       user_emb, item_emb = model.get_all_embeddings(adj)‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ    2. –í—ã—á–∏—Å–ª–∏—Ç—å scores –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä:                    ‚îÇ
‚îÇ       scores = user_emb @ item_emb.T  # [n_users, n_items]
‚îÇ                                                          ‚îÇ
‚îÇ    3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:                         ‚îÇ
‚îÇ       - –í–∑—è—Ç—å —Ç–æ–ø-K –∞–π—Ç–µ–º–æ–≤ (–ø–æ scores)                 ‚îÇ
‚îÇ       - –°—Ä–∞–≤–Ω–∏—Ç—å —Å ground truth (test_data)              ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ    4. –í—ã—á–∏—Å–ª–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏:                                ‚îÇ
‚îÇ       - Recall@K = hits / total_items                   ‚îÇ
‚îÇ       - NDCG@K = normalized discounted cumulative gain  ‚îÇ
‚îÇ       - Coverage = unique_items_recommended / n_items   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### –î–µ—Ç–∞–ª—å–Ω—ã–π –ø–æ—Ç–æ–∫ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏

#### Forward pass (–ø—Ä–∏–º–µ—Ä LightGCN)

```
–í—Ö–æ–¥: adj_matrix [N, N], –≥–¥–µ N = n_users + n_items
      ‚Üì
1. –ù–∞—á–∞–ª—å–Ω—ã–µ embeddings:
   x‚ÇÄ = [user_embedding.weight, item_embedding.weight]
        [n_users, d] + [n_items, d] = [N, d]
      ‚Üì
2. –ì—Ä–∞—Ñ–æ–≤–∞—è —Å–≤–µ—Ä—Ç–∫–∞ (—Å–ª–æ–π 1):
   x‚ÇÅ = adj_matrix @ x‚ÇÄ
       [N, N] @ [N, d] = [N, d]
      ‚Üì
3. –ì—Ä–∞—Ñ–æ–≤–∞—è —Å–≤–µ—Ä—Ç–∫–∞ (—Å–ª–æ–π 2):
   x‚ÇÇ = adj_matrix @ x‚ÇÅ
       [N, N] @ [N, d] = [N, d]
      ‚Üì
4. –ì—Ä–∞—Ñ–æ–≤–∞—è —Å–≤–µ—Ä—Ç–∫–∞ (—Å–ª–æ–π 3):
   x‚ÇÉ = adj_matrix @ x‚ÇÇ
       [N, N] @ [N, d] = [N, d]
      ‚Üì
5. Layer aggregation:
   x_final = mean([x‚ÇÄ, x‚ÇÅ, x‚ÇÇ, x‚ÇÉ])
            [N, d]
      ‚Üì
6. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ:
   user_emb, item_emb = split(x_final, [n_users, n_items])
   user_emb: [n_users, d]
   item_emb: [n_items, d]
```

#### –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ scores

```
–í—Ö–æ–¥: users [batch_size], items [batch_size]
      ‚Üì
1. –ü–æ–ª—É—á–∏—Ç—å embeddings:
   user_emb_all = model.get_all_embeddings(adj_matrix)[0]
                  [n_users, d]
   item_emb_all = model.get_all_embeddings(adj_matrix)[1]
                  [n_items, d]
      ‚Üì
2. –í—ã–±—Ä–∞—Ç—å –Ω—É–∂–Ω—ã–µ embeddings:
   user_emb_selected = user_emb_all[users]
                       [batch_size, d]
   item_emb_selected = item_emb_all[items]
                       [batch_size, d]
      ‚Üì
3. –í—ã—á–∏—Å–ª–∏—Ç—å scores:
   scores = (user_emb_selected * item_emb_selected).sum(dim=1)
            [batch_size, d] * [batch_size, d] = [batch_size]
```

#### –û–±—É—á–µ–Ω–∏–µ (BPR Loss)

```
–í—Ö–æ–¥: user [batch_size], pos_item [batch_size], neg_item [batch_size]
      ‚Üì
1. Forward pass:
   user_emb, item_emb = model(adj_matrix)
      ‚Üì
2. –í—ã—á–∏—Å–ª–∏—Ç—å scores:
   pos_scores = (user_emb[user] * item_emb[pos_item]).sum(1)
                [batch_size]
   neg_scores = (user_emb[user] * item_emb[neg_item]).sum(1)
                [batch_size]
      ‚Üì
3. BPR Loss:
   loss = -log(œÉ(pos_scores - neg_scores))
         –≥–¥–µ œÉ(x) = 1 / (1 + exp(-x))
      ‚Üì
4. Backward:
   loss.backward()
   optimizer.step()
```

---

## üíª –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ü—Ä–∏–º–µ—Ä 1: –û–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏

```python
import torch
from models import LightGCN
from data import RecommendationDataset

# 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
dataset = RecommendationDataset(name="movie_lens")
dataset.load_processed_data()
adj_matrix = dataset.get_torch_adjacency(normalized=True)

# 2. –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
model = LightGCN(
    n_users=dataset.n_users,
    n_items=dataset.n_items,
    embedding_dim=64,
    n_layers=3
)

# 3. Forward pass
user_emb, item_emb = model(adj_matrix)
print(f"User embeddings: {user_emb.shape}")
print(f"Item embeddings: {item_emb.shape}")

# 4. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
users = torch.tensor([0, 1, 2])
items = torch.tensor([0, 1, 2])
scores = model.predict(users, items, adj_matrix)
print(f"Scores: {scores}")
```

### –ü—Ä–∏–º–µ—Ä 2: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

```python
from models import (
    BPR_MF, LightGCN, GCNII, DGR, SVD_GCN, LayerGCN, GroupShuffleGNN
)
from data import RecommendationDataset

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
dataset = RecommendationDataset(name="movie_lens")
dataset.load_processed_data()
adj_matrix = dataset.get_torch_adjacency(normalized=True)

# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
models = {
    'BPR-MF': BPR_MF(dataset.n_users, dataset.n_items, 64),
    'LightGCN': LightGCN(dataset.n_users, dataset.n_items, 64, n_layers=3),
    'GCNII': GCNII(dataset.n_users, dataset.n_items, 64, n_layers=3),
    'DGR': DGR(dataset.n_users, dataset.n_items, 64, n_layers=3),
    'SVD-GCN': SVD_GCN(dataset.n_users, dataset.n_items, 64, n_layers=3),
    'LayerGCN': LayerGCN(dataset.n_users, dataset.n_items, 64, n_layers=3),
    'GroupShuffleGNN': GroupShuffleGNN(
        dataset.n_users, dataset.n_items, 64, n_layers=3, block_size=8
    ),
}

# –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
for name, model in models.items():
    print(f"\n{name}:")
    print(f"  –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {model.get_parameters_count():,}")
    
    # Forward pass
    try:
        if name == 'BPR-MF':
            user_emb, item_emb = model()
        else:
            user_emb, item_emb = model(adj_matrix)
        print(f"  ‚úÖ Forward pass —É—Å–ø–µ—à–µ–Ω")
    except Exception as e:
        print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
```

### –ü—Ä–∏–º–µ—Ä 3: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π

```python
import yaml
from models import LightGCN
from data import RecommendationDataset

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
with open('config/models/lightgcn.yaml', 'r') as f:
    config = yaml.safe_load(f)

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
dataset = RecommendationDataset(name="movie_lens")
dataset.load_processed_data()
adj_matrix = dataset.get_torch_adjacency(normalized=True)

# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
model_config = config['model']
model = LightGCN(
    n_users=dataset.n_users,
    n_items=dataset.n_items,
    **model_config
)

print(f"–ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏: {model_config}")
```

---

## üìä –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–æ–¥–µ–ª–µ–π

| –ú–æ–¥–µ–ª—å | –°–ª–æ–∂–Ω–æ—Å—Ç—å | –ì—Ä–∞—Ñ | Residual | Layer Agg | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å |
|--------|-----------|------|----------|-----------|-------------|
| **BPR-MF** | ‚≠ê | ‚ùå | ‚ùå | ‚ùå | –¢–æ–ª—å–∫–æ embeddings |
| **LightGCN** | ‚≠ê‚≠ê | ‚úÖ | ‚ùå | ‚úÖ | –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π GCN |
| **GCNII** | ‚≠ê‚≠ê | ‚úÖ | ‚úÖ | ‚ùå | Identity + Residual |
| **DGR** | ‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚úÖ | ‚ùå | Desmoothing |
| **SVD-GCN** | ‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚ùå | ‚ùå | SVD –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è |
| **LayerGCN** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚úÖ | ‚úÖ | Layer-wise refinement |
| **GroupShuffleGNN** ‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚úÖ | ‚úÖ | ‚úÖ | –û—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ |

---

## üîç –ö–ª—é—á–µ–≤—ã–µ —Ä–∞–∑–ª–∏—á–∏—è

### 1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≥—Ä–∞—Ñ–∞

- **BPR-MF**: –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≥—Ä–∞—Ñ (—Ç–æ–ª—å–∫–æ embeddings)
- **–û—Å—Ç–∞–ª—å–Ω—ã–µ**: –ò—Å–ø–æ–ª—å–∑—É—é—Ç –≥—Ä–∞—Ñ–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É (adj_matrix)

### 2. Residual connections

- **BPR-MF, LightGCN, SVD-GCN**: –ù–µ—Ç residual
- **GCNII, DGR, LayerGCN, GroupShuffleGNN**: –ï—Å—Ç—å residual

### 3. Layer aggregation

- **BPR-MF, GCNII, DGR, SVD-GCN**: –ù–µ—Ç layer aggregation
- **LightGCN, LayerGCN, GroupShuffleGNN**: –ï—Å—Ç—å layer aggregation

### 4. –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏

- **GCNII**: Identity mapping
- **DGR**: Desmoothing regularization
- **SVD-GCN**: SVD –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è
- **LayerGCN**: Layer-wise refinement
- **GroupShuffleGNN**: –û—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ + Shuffle

---

## üéØ –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫—É—é –º–æ–¥–µ–ª—å

### –î–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ baseline
- **BPR-MF** - —Å–∞–º–∞—è –ø—Ä–æ—Å—Ç–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è

### –î–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
- **LightGCN** - –æ–¥–∏–Ω –∏–∑ –ª—É—á—à–∏—Ö baseline –º–µ—Ç–æ–¥–æ–≤

### –î–ª—è –≥–ª—É–±–æ–∫–∏—Ö —Å–µ—Ç–µ–π (–º–Ω–æ–≥–æ —Å–ª–æ–µ–≤)
- **GCNII** - residual connections
- **DGR** - desmoothing
- **LayerGCN** - layer-wise refinement
- **GroupShuffleGNN** - –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å

### –î–ª—è –±–æ–ª—å—à–∏—Ö –≥—Ä–∞—Ñ–æ–≤
- **SVD-GCN** - —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏—è

### –î–ª—è –≤–∞—à–µ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
- **GroupShuffleGNN** - –≤–∞—à–∞ –º–æ–¥–µ–ª—å —Å –æ—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–º–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è–º–∏

---

## üöÄ –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–æ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤)

### –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–æ–¥–∏–Ω —Ä–∞–∑)

```bash
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
python scripts/prepare_data.py --dataset movie_lens
python scripts/prepare_data.py --dataset book_crossing
python scripts/prepare_data.py --dataset gowalla
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ `data/processed/{dataset}/`
- –ì—Ä–∞—Ñ—ã –≤ `data/graphs/{dataset}/`

### –®–∞–≥ 2: –û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

```python
# scripts/run_experiments.py (–±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω –ø–æ–∑–∂–µ)

from models import (
    BPR_MF, LightGCN, GCNII, DGR, SVD_GCN, LayerGCN, GroupShuffleGNN
)
from data import RecommendationDataset
from training import Trainer
from evaluation import Evaluator

# –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
models_to_test = {
    'BPR-MF': BPR_MF,
    'LightGCN': LightGCN,
    'GCNII': GCNII,
    'DGR': DGR,
    'SVD-GCN': SVD_GCN,
    'LayerGCN': LayerGCN,
    'GroupShuffleGNN': GroupShuffleGNN,
}

# –î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
for dataset_name in ['movie_lens', 'book_crossing', 'gowalla']:
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    dataset = RecommendationDataset(name=dataset_name)
    dataset.load_processed_data()
    adj_matrix = dataset.get_torch_adjacency(normalized=True)
    
    # –î–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    for model_name, ModelClass in models_to_test.items():
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        model = ModelClass(
            n_users=dataset.n_users,
            n_items=dataset.n_items,
            embedding_dim=64,
            n_layers=3
        )
        
        # –û–±—É—á–∞–µ–º
        trainer = Trainer(model, dataset, config)
        trainer.train()
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º
        evaluator = Evaluator()
        metrics = evaluator.evaluate(model, dataset.test_data)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        save_results(model_name, dataset_name, metrics)
```

### –®–∞–≥ 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

```python
# –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
results = load_all_results()

# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –º–µ—Ç—Ä–∏–∫–∞–º
for metric in ['Recall@10', 'NDCG@10']:
    print(f"\n{metric}:")
    for model_name in models_to_test.keys():
        mean_score = results[model_name][metric]['mean']
        std_score = results[model_name][metric]['std']
        print(f"  {model_name:20s} {mean_score:.4f} ¬± {std_score:.4f}")

# –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
perform_statistical_tests(results)
```

---

## üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

### –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

```
–î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞:
  –î–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏:
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ seed (5 —Ä–∞–∑):
      1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
      2. –û–±—É—á–µ–Ω–∏–µ
      3. –û—Ü–µ–Ω–∫–∞ –Ω–∞ test set
      4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
    
    –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (mean ¬± std)
```

### –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 2: Depth Analysis

```
–î–ª—è GroupShuffleGNN:
  –î–ª—è n_layers –≤ [2, 4, 8, 16]:
    –û–±—É—á–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞
    –ê–Ω–∞–ª–∏–∑ over-smoothing –º–µ—Ç—Ä–∏–∫
```

### –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 3: Ablation Studies

```
–î–ª—è GroupShuffleGNN:
  - –ë–µ–∑ residual connections
  - –ë–µ–∑ shuffle
  - –ë–µ–∑ layer aggregation
  - –†–∞–∑–Ω—ã–µ block_size
```

---

## üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

### –ï–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π

–í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–∞—Å–ª–µ–¥—É—é—Ç—Å—è –æ—Ç `BaseRecommender` –∏ –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –º–µ—Ç–æ–¥—ã:

```python
class BaseRecommender:
    def forward(adj_matrix) -> (user_emb, item_emb)
    def predict(users, items, adj_matrix) -> scores
    def get_all_embeddings(adj_matrix) -> (user_emb, item_emb)
    def get_parameters_count() -> int
    def reset_parameters()
```

### –†–∞–∑–ª–∏—á–∏—è –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏

| –ú–æ–¥–µ–ª—å | –¢—Ä–µ–±—É–µ—Ç adj_matrix? | –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ |
|--------|---------------------|-------------|
| **BPR-MF** | ‚ùå –ù–µ—Ç | –ú–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –≥—Ä–∞—Ñ–∞ |
| **–û—Å—Ç–∞–ª—å–Ω—ã–µ** | ‚úÖ –î–∞ | –¢—Ä–µ–±—É—é—Ç –≥—Ä–∞—Ñ –¥–ª—è forward pass |

### –û–±—Ä–∞–±–æ—Ç–∫–∞ sparse –º–∞—Ç—Ä–∏—Ü

–í—Å–µ –º–æ–¥–µ–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –∫–∞–∫ sparse, —Ç–∞–∫ –∏ dense adjacency matrices:

```python
# Sparse (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –±–æ–ª—å—à–∏—Ö –≥—Ä–∞—Ñ–æ–≤)
adj_matrix = dataset.get_torch_adjacency(normalized=True)  # sparse

# Dense (–¥–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö –≥—Ä–∞—Ñ–æ–≤)
adj_matrix = adj_matrix.to_dense()  # –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
```

---

## üìà –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã

### –ü–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π

1. **BPR-MF**: –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å (Recall@10 ‚âà 0.045-0.052)
2. **LightGCN**: –°–∏–ª—å–Ω—ã–π baseline (Recall@10 ‚âà 0.058-0.065)
3. **GCNII, DGR, SVD-GCN**: –°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å (Recall@10 ‚âà 0.060-0.068)
4. **LayerGCN**: –í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å (Recall@10 ‚âà 0.070-0.076)
5. **GroupShuffleGNN**: –í–∞—à–∞ –º–æ–¥–µ–ª—å (–æ–∂–∏–¥–∞–µ—Ç—Å—è –ª—É—á—à–µ –∏–ª–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ LayerGCN)

### –ü–æ –±–æ—Ä—å–±–µ —Å over-smoothing

- **BPR-MF, LightGCN**: –ù–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–µ—Ö–Ω–∏–∫
- **GCNII**: Residual connections
- **DGR**: Desmoothing regularization
- **LayerGCN**: Layer-wise refinement
- **GroupShuffleGNN**: –û—Ä—Ç–æ–≥–æ–Ω–∞–ª—å–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (–Ω–æ–≤–∞—è —Ç–µ—Ö–Ω–∏–∫–∞)

---

## ‚úÖ –ò—Ç–æ–≥

–í—Å–µ –º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç **–µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å** –∏ –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –æ–¥–∏–Ω–∞–∫–æ–≤–æ:

1. **–°–æ–∑–¥–∞–Ω–∏–µ**: `model = ModelClass(n_users, n_items, ...)`
2. **Forward**: `user_emb, item_emb = model(adj_matrix)`
3. **–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ**: `scores = model.predict(users, items, adj_matrix)`
4. **Embeddings**: `user_emb, item_emb = model.get_all_embeddings(adj_matrix)`

**–†–∞–∑–ª–∏—á–∏—è —Ç–æ–ª—å–∫–æ –≤ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö**, –Ω–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –¥–ª—è –≤—Å–µ—Ö!

–≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç:
- ‚úÖ –õ–µ–≥–∫–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –º–æ–¥–µ–ª–∏
- ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –∫–æ–¥ –æ–±—É—á–µ–Ω–∏—è
- ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –∫–æ–¥ –æ—Ü–µ–Ω–∫–∏
- ‚úÖ –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- **–ö–æ–¥ –º–æ–¥–µ–ª–µ–π**: `src/models/`
- **–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏**: `config/models/`
- **–¢–µ—Å—Ç—ã**: `scripts/test_all_models.py`
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –¥–∞–Ω–Ω—ã–º**: `src/data/README.md`

